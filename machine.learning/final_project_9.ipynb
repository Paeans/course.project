{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_validate, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('hotel_bookings.csv')\n",
    "data_cln = data.fillna({'children': 0.0, 'country': 'Unknown', 'agent':0, 'company': 0})\n",
    "data_cln['meal'].replace('Undefined', 'SC', inplace = True)\n",
    "\n",
    "num_features = [\"lead_time\",\"arrival_date_week_number\",\"arrival_date_day_of_month\",\n",
    "                \"stays_in_weekend_nights\",\"stays_in_week_nights\",\"adults\",\"children\",\n",
    "                \"babies\",\"is_repeated_guest\", \"previous_cancellations\",\n",
    "                \"previous_bookings_not_canceled\",\"agent\",\"company\",\n",
    "                \"required_car_parking_spaces\", \"total_of_special_requests\", \"adr\"]\n",
    "\n",
    "cat_features = [\"arrival_date_month\",\"meal\",\"market_segment\",\n",
    "                \"distribution_channel\",\"reserved_room_type\",\"deposit_type\",\"customer_type\"]\n",
    "\n",
    "# Separate features and predicted value\n",
    "features = num_features + cat_features\n",
    "\n",
    "# preprocess numerical feats:\n",
    "# for most num cols, except the dates, 0 is the most logical choice as fill value\n",
    "# and here no dates are missing.\n",
    "num_transformer = SimpleImputer(strategy=\"constant\")\n",
    "\n",
    "# Preprocessing for categorical features:\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical features:\n",
    "preprocessor = ColumnTransformer(transformers=[(\"num\", num_transformer, num_features),\n",
    "                                               (\"cat\", cat_transformer, cat_features)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resort_data = data_cln[data_cln.hotel == 'Resort Hotel']\n",
    "city_data = data_cln[data_cln.hotel == 'City Hotel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_1():\n",
    "    inputs = keras.Input(shape=(62,), dtype = \"float32\")\n",
    "    \n",
    "    x = layers.Dense(256)(inputs)\n",
    "#     x = layers.Dense(256)(x)\n",
    "#     x = layers.Dense(256)(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = layers.Dense(64)(x)\n",
    "    x = layers.Dense(32)(x)\n",
    "    x = layers.Dense(16)(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid',\n",
    "                    kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4))(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    # model.summary()\n",
    "\n",
    "    model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\", \"AUC\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kfolds = 10 \n",
    "# kf = KFold(n_splits=kfolds, shuffle=True, random_state=42)\n",
    "# accuracy_res = []\n",
    "# pred_res = []\n",
    "# for train_index, test_index in kf.split(y):\n",
    "#     train_x = X[train_index]\n",
    "#     train_y = y[train_index]\n",
    "    \n",
    "#     test_x = X[test_index]\n",
    "#     test_y = y[test_index]\n",
    "    \n",
    "#     model = test_model_1()\n",
    "    \n",
    "#     history = model.fit(train_x, train_y, batch_size=64, epochs=30, )\n",
    "#     pred_y = model.predict(test_x)\n",
    "#     pred_res.append({'pred': pred_y, 'real': test_y})\n",
    "#     tmp = []\n",
    "#     for i in np.arange(0, 1, 0.01):\n",
    "#         tmp_y = np.zeros(pred_y.shape)\n",
    "#         tmp_y[pred_y > i] = 1\n",
    "#         tmp.append(accuracy_score(test_y, tmp_y))\n",
    "#     print(max(tmp))\n",
    "#     accuracy_res.append(max(tmp))\n",
    "        \n",
    "# accuracy_val = np.array(accuracy_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "626/626 - 4s - loss: 1.3754 - accuracy: 0.7140 - auc: 0.6600\n",
      "Epoch 2/30\n",
      "626/626 - 4s - loss: 0.4918 - accuracy: 0.7678 - auc: 0.7763\n",
      "Epoch 3/30\n",
      "626/626 - 4s - loss: 0.4613 - accuracy: 0.7818 - auc: 0.8012\n",
      "Epoch 4/30\n",
      "626/626 - 4s - loss: 0.4540 - accuracy: 0.7861 - auc: 0.8079\n",
      "Epoch 5/30\n",
      "626/626 - 4s - loss: 0.4503 - accuracy: 0.7888 - auc: 0.8110\n",
      "Epoch 6/30\n",
      "626/626 - 4s - loss: 0.4411 - accuracy: 0.7920 - auc: 0.8193\n",
      "Epoch 7/30\n",
      "626/626 - 4s - loss: 0.4391 - accuracy: 0.7946 - auc: 0.8200\n",
      "Epoch 8/30\n",
      "626/626 - 4s - loss: 0.4404 - accuracy: 0.7921 - auc: 0.8190\n",
      "Epoch 9/30\n",
      "626/626 - 4s - loss: 0.4357 - accuracy: 0.7976 - auc: 0.8230\n",
      "Epoch 10/30\n",
      "626/626 - 4s - loss: 0.4323 - accuracy: 0.7993 - auc: 0.8254\n",
      "Epoch 11/30\n",
      "626/626 - 4s - loss: 0.4349 - accuracy: 0.7975 - auc: 0.8232\n",
      "Epoch 12/30\n",
      "626/626 - 4s - loss: 0.4271 - accuracy: 0.8025 - auc: 0.8298\n",
      "Epoch 13/30\n",
      "626/626 - 5s - loss: 0.4265 - accuracy: 0.8017 - auc: 0.8295\n",
      "Epoch 14/30\n",
      "626/626 - 4s - loss: 0.4259 - accuracy: 0.8031 - auc: 0.8296\n",
      "Epoch 15/30\n",
      "626/626 - 4s - loss: 0.4257 - accuracy: 0.8021 - auc: 0.8305\n",
      "Epoch 16/30\n",
      "626/626 - 4s - loss: 0.4249 - accuracy: 0.8024 - auc: 0.8308\n",
      "Epoch 17/30\n",
      "626/626 - 4s - loss: 0.4229 - accuracy: 0.8039 - auc: 0.8325\n",
      "Epoch 18/30\n",
      "626/626 - 4s - loss: 0.4238 - accuracy: 0.8038 - auc: 0.8323\n",
      "Epoch 19/30\n",
      "626/626 - 4s - loss: 0.4208 - accuracy: 0.8073 - auc: 0.8345\n",
      "Epoch 20/30\n",
      "626/626 - 4s - loss: 0.4207 - accuracy: 0.8065 - auc: 0.8343\n",
      "Epoch 21/30\n",
      "626/626 - 4s - loss: 0.4203 - accuracy: 0.8065 - auc: 0.8349\n",
      "Epoch 22/30\n",
      "626/626 - 4s - loss: 0.4202 - accuracy: 0.8054 - auc: 0.8346\n",
      "Epoch 23/30\n",
      "626/626 - 5s - loss: 0.4214 - accuracy: 0.8059 - auc: 0.8338\n",
      "Epoch 24/30\n",
      "626/626 - 5s - loss: 0.4193 - accuracy: 0.8066 - auc: 0.8349\n",
      "Epoch 25/30\n",
      "626/626 - 5s - loss: 0.4201 - accuracy: 0.8083 - auc: 0.8346\n",
      "Epoch 26/30\n",
      "626/626 - 4s - loss: 0.4190 - accuracy: 0.8085 - auc: 0.8357\n",
      "Epoch 27/30\n",
      "626/626 - 4s - loss: 0.4172 - accuracy: 0.8088 - auc: 0.8368\n",
      "Epoch 28/30\n",
      "626/626 - 4s - loss: 0.4181 - accuracy: 0.8073 - auc: 0.8361\n",
      "Epoch 29/30\n",
      "626/626 - 4s - loss: 0.4176 - accuracy: 0.8070 - auc: 0.8368\n",
      "Epoch 30/30\n",
      "626/626 - 4s - loss: 0.4178 - accuracy: 0.8096 - auc: 0.8362\n",
      "Epoch 1/30\n",
      "626/626 - 4s - loss: 1.0115 - accuracy: 0.7224 - auc: 0.6815\n",
      "Epoch 2/30\n",
      "626/626 - 4s - loss: 0.4867 - accuracy: 0.7718 - auc: 0.7773\n",
      "Epoch 3/30\n",
      "626/626 - 4s - loss: 0.4599 - accuracy: 0.7847 - auc: 0.8014\n",
      "Epoch 4/30\n",
      "626/626 - 4s - loss: 0.4517 - accuracy: 0.7872 - auc: 0.8093\n",
      "Epoch 5/30\n",
      "626/626 - 4s - loss: 0.4422 - accuracy: 0.7932 - auc: 0.8176\n",
      "Epoch 6/30\n",
      "626/626 - 4s - loss: 0.4406 - accuracy: 0.7931 - auc: 0.8187\n",
      "Epoch 7/30\n",
      "626/626 - 4s - loss: 0.4364 - accuracy: 0.7966 - auc: 0.8225\n",
      "Epoch 8/30\n",
      "626/626 - 4s - loss: 0.4343 - accuracy: 0.7973 - auc: 0.8237\n",
      "Epoch 9/30\n",
      "626/626 - 4s - loss: 0.4317 - accuracy: 0.7991 - auc: 0.8251\n",
      "Epoch 10/30\n",
      "626/626 - 4s - loss: 0.4321 - accuracy: 0.7986 - auc: 0.8248\n",
      "Epoch 11/30\n",
      "626/626 - 4s - loss: 0.4287 - accuracy: 0.8002 - auc: 0.8282\n",
      "Epoch 12/30\n",
      "626/626 - 4s - loss: 0.4269 - accuracy: 0.8014 - auc: 0.8291\n",
      "Epoch 13/30\n",
      "626/626 - 5s - loss: 0.4273 - accuracy: 0.8020 - auc: 0.8294\n",
      "Epoch 14/30\n",
      "626/626 - 5s - loss: 0.4265 - accuracy: 0.8017 - auc: 0.8294\n",
      "Epoch 15/30\n",
      "626/626 - 4s - loss: 0.4243 - accuracy: 0.8028 - auc: 0.8314\n",
      "Epoch 16/30\n",
      "626/626 - 4s - loss: 0.4256 - accuracy: 0.8028 - auc: 0.8300\n",
      "Epoch 17/30\n",
      "626/626 - 4s - loss: 0.4221 - accuracy: 0.8050 - auc: 0.8337\n",
      "Epoch 18/30\n",
      "626/626 - 4s - loss: 0.4211 - accuracy: 0.8075 - auc: 0.8340\n",
      "Epoch 19/30\n",
      "626/626 - 4s - loss: 0.4210 - accuracy: 0.8060 - auc: 0.8344\n",
      "Epoch 20/30\n",
      "626/626 - 4s - loss: 0.4216 - accuracy: 0.8053 - auc: 0.8335\n",
      "Epoch 21/30\n",
      "626/626 - 4s - loss: 0.4223 - accuracy: 0.8050 - auc: 0.8331\n",
      "Epoch 22/30\n",
      "626/626 - 4s - loss: 0.4216 - accuracy: 0.8038 - auc: 0.8335\n",
      "Epoch 23/30\n",
      "626/626 - 4s - loss: 0.4195 - accuracy: 0.8075 - auc: 0.8355\n",
      "Epoch 24/30\n",
      "626/626 - 4s - loss: 0.4197 - accuracy: 0.8061 - auc: 0.8351\n",
      "Epoch 25/30\n",
      "626/626 - 4s - loss: 0.4190 - accuracy: 0.8075 - auc: 0.8351\n",
      "Epoch 26/30\n",
      "626/626 - 4s - loss: 0.4190 - accuracy: 0.8078 - auc: 0.8355\n",
      "Epoch 27/30\n",
      "626/626 - 4s - loss: 0.4187 - accuracy: 0.8059 - auc: 0.8362\n",
      "Epoch 28/30\n",
      "626/626 - 4s - loss: 0.4191 - accuracy: 0.8072 - auc: 0.8354\n",
      "Epoch 29/30\n",
      "626/626 - 5s - loss: 0.4170 - accuracy: 0.8087 - auc: 0.8365\n",
      "Epoch 30/30\n",
      "626/626 - 4s - loss: 0.4176 - accuracy: 0.8072 - auc: 0.8366\n",
      "Epoch 1/30\n",
      "626/626 - 4s - loss: 1.0874 - accuracy: 0.7191 - auc: 0.6689\n",
      "Epoch 2/30\n",
      "626/626 - 4s - loss: 0.4868 - accuracy: 0.7702 - auc: 0.7788\n",
      "Epoch 3/30\n",
      "626/626 - 4s - loss: 0.4668 - accuracy: 0.7819 - auc: 0.7944\n",
      "Epoch 4/30\n",
      "626/626 - 4s - loss: 0.4549 - accuracy: 0.7837 - auc: 0.8070\n",
      "Epoch 5/30\n",
      "626/626 - 4s - loss: 0.4436 - accuracy: 0.7911 - auc: 0.8165\n",
      "Epoch 6/30\n",
      "626/626 - 4s - loss: 0.4417 - accuracy: 0.7915 - auc: 0.8177\n",
      "Epoch 7/30\n",
      "626/626 - 4s - loss: 0.4392 - accuracy: 0.7934 - auc: 0.8195\n",
      "Epoch 8/30\n",
      "626/626 - 4s - loss: 0.4350 - accuracy: 0.7970 - auc: 0.8233\n",
      "Epoch 9/30\n",
      "626/626 - 4s - loss: 0.4338 - accuracy: 0.7954 - auc: 0.8237\n",
      "Epoch 10/30\n",
      "626/626 - 4s - loss: 0.4337 - accuracy: 0.7970 - auc: 0.8243\n",
      "Epoch 11/30\n",
      "626/626 - 4s - loss: 0.4285 - accuracy: 0.7995 - auc: 0.8283\n",
      "Epoch 12/30\n",
      "626/626 - 4s - loss: 0.4292 - accuracy: 0.8007 - auc: 0.8269\n",
      "Epoch 13/30\n",
      "626/626 - 4s - loss: 0.4230 - accuracy: 0.8056 - auc: 0.8323\n",
      "Epoch 14/30\n",
      "626/626 - 4s - loss: 0.4274 - accuracy: 0.8013 - auc: 0.8296\n",
      "Epoch 15/30\n",
      "626/626 - 4s - loss: 0.4240 - accuracy: 0.8034 - auc: 0.8317\n",
      "Epoch 16/30\n",
      "626/626 - 4s - loss: 0.4242 - accuracy: 0.8029 - auc: 0.8319\n",
      "Epoch 17/30\n",
      "626/626 - 4s - loss: 0.4224 - accuracy: 0.8027 - auc: 0.8329\n",
      "Epoch 18/30\n",
      "626/626 - 5s - loss: 0.4215 - accuracy: 0.8065 - auc: 0.8337\n",
      "Epoch 19/30\n",
      "626/626 - 5s - loss: 0.4204 - accuracy: 0.8073 - auc: 0.8340\n",
      "Epoch 20/30\n",
      "626/626 - 5s - loss: 0.4228 - accuracy: 0.8041 - auc: 0.8328\n",
      "Epoch 21/30\n",
      "626/626 - 4s - loss: 0.4196 - accuracy: 0.8079 - auc: 0.8348\n",
      "Epoch 22/30\n",
      "626/626 - 4s - loss: 0.4210 - accuracy: 0.8063 - auc: 0.8342\n",
      "Epoch 23/30\n",
      "626/626 - 4s - loss: 0.4190 - accuracy: 0.8090 - auc: 0.8360\n",
      "Epoch 24/30\n",
      "626/626 - 4s - loss: 0.4192 - accuracy: 0.8056 - auc: 0.8354\n",
      "Epoch 25/30\n",
      "626/626 - 4s - loss: 0.4193 - accuracy: 0.8070 - auc: 0.8358\n",
      "Epoch 26/30\n",
      "626/626 - 4s - loss: 0.4186 - accuracy: 0.8080 - auc: 0.8359\n",
      "Epoch 27/30\n",
      "626/626 - 4s - loss: 0.4204 - accuracy: 0.8054 - auc: 0.8344\n",
      "Epoch 28/30\n",
      "626/626 - 4s - loss: 0.4173 - accuracy: 0.8072 - auc: 0.8371\n",
      "Epoch 29/30\n",
      "626/626 - 4s - loss: 0.4171 - accuracy: 0.8095 - auc: 0.8367\n",
      "Epoch 30/30\n",
      "626/626 - 4s - loss: 0.4162 - accuracy: 0.8097 - auc: 0.8379\n",
      "Epoch 1/30\n",
      "626/626 - 4s - loss: 1.1843 - accuracy: 0.7236 - auc: 0.6743\n",
      "Epoch 2/30\n",
      "626/626 - 4s - loss: 0.4824 - accuracy: 0.7744 - auc: 0.7828\n",
      "Epoch 3/30\n",
      "626/626 - 4s - loss: 0.4618 - accuracy: 0.7825 - auc: 0.7998\n",
      "Epoch 4/30\n",
      "626/626 - 4s - loss: 0.4485 - accuracy: 0.7895 - auc: 0.8127\n",
      "Epoch 5/30\n",
      "626/626 - 4s - loss: 0.4478 - accuracy: 0.7892 - auc: 0.8140\n",
      "Epoch 6/30\n",
      "626/626 - 4s - loss: 0.4409 - accuracy: 0.7928 - auc: 0.8187\n",
      "Epoch 7/30\n",
      "626/626 - 4s - loss: 0.4436 - accuracy: 0.7895 - auc: 0.8164\n",
      "Epoch 8/30\n",
      "626/626 - 4s - loss: 0.4333 - accuracy: 0.7959 - auc: 0.8245\n",
      "Epoch 9/30\n",
      "626/626 - 4s - loss: 0.4345 - accuracy: 0.7956 - auc: 0.8235\n",
      "Epoch 10/30\n",
      "626/626 - 4s - loss: 0.4303 - accuracy: 0.7988 - auc: 0.8263\n",
      "Epoch 11/30\n",
      "626/626 - 4s - loss: 0.4297 - accuracy: 0.7996 - auc: 0.8272\n",
      "Epoch 12/30\n",
      "626/626 - 4s - loss: 0.4272 - accuracy: 0.8013 - auc: 0.8294\n",
      "Epoch 13/30\n",
      "626/626 - 4s - loss: 0.4266 - accuracy: 0.8013 - auc: 0.8300\n",
      "Epoch 14/30\n",
      "626/626 - 4s - loss: 0.4240 - accuracy: 0.8042 - auc: 0.8320\n",
      "Epoch 15/30\n",
      "626/626 - 4s - loss: 0.4252 - accuracy: 0.8008 - auc: 0.8303\n",
      "Epoch 16/30\n",
      "626/626 - 4s - loss: 0.4262 - accuracy: 0.8012 - auc: 0.8298\n",
      "Epoch 17/30\n",
      "626/626 - 4s - loss: 0.4233 - accuracy: 0.8047 - auc: 0.8320\n",
      "Epoch 18/30\n",
      "626/626 - 4s - loss: 0.4225 - accuracy: 0.8036 - auc: 0.8329\n",
      "Epoch 19/30\n",
      "626/626 - 4s - loss: 0.4212 - accuracy: 0.8056 - auc: 0.8339\n",
      "Epoch 20/30\n",
      "626/626 - 4s - loss: 0.4240 - accuracy: 0.8031 - auc: 0.8310\n",
      "Epoch 21/30\n",
      "626/626 - 4s - loss: 0.4196 - accuracy: 0.8072 - auc: 0.8356\n",
      "Epoch 22/30\n",
      "626/626 - 4s - loss: 0.4200 - accuracy: 0.8072 - auc: 0.8353\n",
      "Epoch 23/30\n",
      "626/626 - 4s - loss: 0.4191 - accuracy: 0.8066 - auc: 0.8355\n",
      "Epoch 24/30\n",
      "626/626 - 4s - loss: 0.4195 - accuracy: 0.8065 - auc: 0.8353\n",
      "Epoch 25/30\n",
      "626/626 - 4s - loss: 0.4189 - accuracy: 0.8073 - auc: 0.8360\n",
      "Epoch 26/30\n",
      "626/626 - 4s - loss: 0.4180 - accuracy: 0.8099 - auc: 0.8364\n",
      "Epoch 27/30\n",
      "626/626 - 4s - loss: 0.4193 - accuracy: 0.8079 - auc: 0.8351\n",
      "Epoch 28/30\n",
      "626/626 - 4s - loss: 0.4164 - accuracy: 0.8084 - auc: 0.8378\n",
      "Epoch 29/30\n",
      "626/626 - 4s - loss: 0.4169 - accuracy: 0.8084 - auc: 0.8369\n",
      "Epoch 30/30\n",
      "626/626 - 4s - loss: 0.4190 - accuracy: 0.8064 - auc: 0.8357\n",
      "Epoch 1/30\n",
      "626/626 - 4s - loss: 1.1375 - accuracy: 0.7178 - auc: 0.6622\n",
      "Epoch 2/30\n",
      "626/626 - 4s - loss: 0.4852 - accuracy: 0.7744 - auc: 0.7789\n",
      "Epoch 3/30\n",
      "626/626 - 4s - loss: 0.4684 - accuracy: 0.7810 - auc: 0.7952\n",
      "Epoch 4/30\n",
      "626/626 - 4s - loss: 0.4578 - accuracy: 0.7849 - auc: 0.8034\n",
      "Epoch 5/30\n",
      "626/626 - 4s - loss: 0.4517 - accuracy: 0.7875 - auc: 0.8090\n",
      "Epoch 6/30\n",
      "626/626 - 4s - loss: 0.4409 - accuracy: 0.7949 - auc: 0.8189\n",
      "Epoch 7/30\n",
      "626/626 - 4s - loss: 0.4355 - accuracy: 0.7943 - auc: 0.8228\n",
      "Epoch 8/30\n",
      "626/626 - 4s - loss: 0.4422 - accuracy: 0.7926 - auc: 0.8179\n",
      "Epoch 9/30\n",
      "626/626 - 4s - loss: 0.4353 - accuracy: 0.7958 - auc: 0.8231\n",
      "Epoch 10/30\n",
      "626/626 - 4s - loss: 0.4316 - accuracy: 0.7991 - auc: 0.8256\n",
      "Epoch 11/30\n",
      "626/626 - 4s - loss: 0.4303 - accuracy: 0.7982 - auc: 0.8262\n",
      "Epoch 12/30\n",
      "626/626 - 4s - loss: 0.4301 - accuracy: 0.7990 - auc: 0.8260\n",
      "Epoch 13/30\n",
      "626/626 - 4s - loss: 0.4278 - accuracy: 0.8013 - auc: 0.8285\n",
      "Epoch 14/30\n",
      "626/626 - 4s - loss: 0.4263 - accuracy: 0.8009 - auc: 0.8298\n",
      "Epoch 15/30\n",
      "626/626 - 4s - loss: 0.4249 - accuracy: 0.8036 - auc: 0.8311\n",
      "Epoch 16/30\n",
      "626/626 - 4s - loss: 0.4229 - accuracy: 0.8034 - auc: 0.8327\n",
      "Epoch 17/30\n",
      "626/626 - 4s - loss: 0.4243 - accuracy: 0.8038 - auc: 0.8317\n",
      "Epoch 18/30\n",
      "626/626 - 4s - loss: 0.4228 - accuracy: 0.8036 - auc: 0.8330\n",
      "Epoch 19/30\n",
      "626/626 - 4s - loss: 0.4212 - accuracy: 0.8061 - auc: 0.8344\n",
      "Epoch 20/30\n",
      "626/626 - 4s - loss: 0.4218 - accuracy: 0.8051 - auc: 0.8336\n",
      "Epoch 21/30\n",
      "626/626 - 4s - loss: 0.4213 - accuracy: 0.8060 - auc: 0.8338\n",
      "Epoch 22/30\n",
      "626/626 - 4s - loss: 0.4207 - accuracy: 0.8055 - auc: 0.8348\n",
      "Epoch 23/30\n",
      "626/626 - 4s - loss: 0.4195 - accuracy: 0.8080 - auc: 0.8348\n",
      "Epoch 24/30\n",
      "626/626 - 4s - loss: 0.4197 - accuracy: 0.8071 - auc: 0.8350\n",
      "Epoch 25/30\n",
      "626/626 - 4s - loss: 0.4207 - accuracy: 0.8073 - auc: 0.8339\n",
      "Epoch 26/30\n",
      "626/626 - 4s - loss: 0.4183 - accuracy: 0.8086 - auc: 0.8360\n",
      "Epoch 27/30\n",
      "626/626 - 4s - loss: 0.4197 - accuracy: 0.8073 - auc: 0.8350\n",
      "Epoch 28/30\n",
      "626/626 - 4s - loss: 0.4174 - accuracy: 0.8069 - auc: 0.8367\n",
      "Epoch 29/30\n",
      "626/626 - 4s - loss: 0.4182 - accuracy: 0.8081 - auc: 0.8362\n",
      "Epoch 30/30\n",
      "626/626 - 4s - loss: 0.4172 - accuracy: 0.8066 - auc: 0.8372\n",
      "Epoch 1/30\n",
      "626/626 - 4s - loss: 1.1961 - accuracy: 0.7201 - auc: 0.6707\n",
      "Epoch 2/30\n",
      "626/626 - 4s - loss: 0.4896 - accuracy: 0.7711 - auc: 0.7748\n",
      "Epoch 3/30\n",
      "626/626 - 4s - loss: 0.4615 - accuracy: 0.7827 - auc: 0.8005\n",
      "Epoch 4/30\n",
      "626/626 - 4s - loss: 0.4479 - accuracy: 0.7916 - auc: 0.8126\n",
      "Epoch 5/30\n",
      "626/626 - 4s - loss: 0.4420 - accuracy: 0.7931 - auc: 0.8173\n",
      "Epoch 6/30\n",
      "626/626 - 4s - loss: 0.4429 - accuracy: 0.7921 - auc: 0.8170\n",
      "Epoch 7/30\n",
      "626/626 - 4s - loss: 0.4385 - accuracy: 0.7953 - auc: 0.8203\n",
      "Epoch 8/30\n",
      "626/626 - 4s - loss: 0.4431 - accuracy: 0.7925 - auc: 0.8161\n",
      "Epoch 9/30\n",
      "626/626 - 4s - loss: 0.4314 - accuracy: 0.7999 - auc: 0.8257\n",
      "Epoch 10/30\n",
      "626/626 - 4s - loss: 0.4304 - accuracy: 0.7992 - auc: 0.8271\n",
      "Epoch 11/30\n",
      "626/626 - 4s - loss: 0.4303 - accuracy: 0.7999 - auc: 0.8273\n",
      "Epoch 12/30\n",
      "626/626 - 4s - loss: 0.4265 - accuracy: 0.8016 - auc: 0.8295\n",
      "Epoch 13/30\n",
      "626/626 - 4s - loss: 0.4258 - accuracy: 0.8015 - auc: 0.8295\n",
      "Epoch 14/30\n",
      "626/626 - 4s - loss: 0.4291 - accuracy: 0.8006 - auc: 0.8275\n",
      "Epoch 15/30\n",
      "626/626 - 4s - loss: 0.4222 - accuracy: 0.8043 - auc: 0.8331\n",
      "Epoch 16/30\n",
      "626/626 - 4s - loss: 0.4238 - accuracy: 0.8051 - auc: 0.8319\n",
      "Epoch 17/30\n",
      "626/626 - 4s - loss: 0.4234 - accuracy: 0.8057 - auc: 0.8321\n",
      "Epoch 18/30\n",
      "626/626 - 4s - loss: 0.4221 - accuracy: 0.8044 - auc: 0.8339\n",
      "Epoch 19/30\n",
      "626/626 - 4s - loss: 0.4218 - accuracy: 0.8048 - auc: 0.8333\n",
      "Epoch 20/30\n",
      "626/626 - 4s - loss: 0.4235 - accuracy: 0.8017 - auc: 0.8324\n",
      "Epoch 21/30\n",
      "626/626 - 4s - loss: 0.4187 - accuracy: 0.8092 - auc: 0.8355\n",
      "Epoch 22/30\n",
      "626/626 - 4s - loss: 0.4207 - accuracy: 0.8057 - auc: 0.8340\n",
      "Epoch 23/30\n",
      "626/626 - 4s - loss: 0.4182 - accuracy: 0.8069 - auc: 0.8366\n",
      "Epoch 24/30\n",
      "626/626 - 4s - loss: 0.4193 - accuracy: 0.8077 - auc: 0.8359\n",
      "Epoch 25/30\n",
      "626/626 - 4s - loss: 0.4175 - accuracy: 0.8082 - auc: 0.8368\n",
      "Epoch 26/30\n",
      "626/626 - 4s - loss: 0.4173 - accuracy: 0.8096 - auc: 0.8369\n",
      "Epoch 27/30\n",
      "626/626 - 4s - loss: 0.4175 - accuracy: 0.8082 - auc: 0.8366\n",
      "Epoch 28/30\n",
      "626/626 - 4s - loss: 0.4177 - accuracy: 0.8076 - auc: 0.8367\n",
      "Epoch 29/30\n",
      "626/626 - 4s - loss: 0.4175 - accuracy: 0.8092 - auc: 0.8370\n",
      "Epoch 30/30\n",
      "626/626 - 4s - loss: 0.4185 - accuracy: 0.8075 - auc: 0.8361\n",
      "Epoch 1/30\n",
      "626/626 - 4s - loss: 1.2047 - accuracy: 0.7150 - auc: 0.6641\n",
      "Epoch 2/30\n",
      "626/626 - 4s - loss: 0.4839 - accuracy: 0.7724 - auc: 0.7817\n",
      "Epoch 3/30\n",
      "626/626 - 4s - loss: 0.4695 - accuracy: 0.7793 - auc: 0.7948\n",
      "Epoch 4/30\n",
      "626/626 - 4s - loss: 0.4631 - accuracy: 0.7822 - auc: 0.8008\n",
      "Epoch 5/30\n",
      "626/626 - 4s - loss: 0.4470 - accuracy: 0.7900 - auc: 0.8133\n",
      "Epoch 6/30\n",
      "626/626 - 4s - loss: 0.4437 - accuracy: 0.7922 - auc: 0.8172\n",
      "Epoch 7/30\n",
      "626/626 - 4s - loss: 0.4450 - accuracy: 0.7922 - auc: 0.8164\n",
      "Epoch 8/30\n",
      "626/626 - 4s - loss: 0.4393 - accuracy: 0.7949 - auc: 0.8192\n",
      "Epoch 9/30\n",
      "626/626 - 4s - loss: 0.4348 - accuracy: 0.7974 - auc: 0.8239\n",
      "Epoch 10/30\n",
      "626/626 - 4s - loss: 0.4355 - accuracy: 0.7953 - auc: 0.8222\n",
      "Epoch 11/30\n",
      "626/626 - 4s - loss: 0.4363 - accuracy: 0.7967 - auc: 0.8226\n",
      "Epoch 12/30\n",
      "626/626 - 4s - loss: 0.4266 - accuracy: 0.8017 - auc: 0.8300\n",
      "Epoch 13/30\n",
      "626/626 - 4s - loss: 0.4302 - accuracy: 0.7979 - auc: 0.8267\n",
      "Epoch 14/30\n",
      "626/626 - 4s - loss: 0.4264 - accuracy: 0.8021 - auc: 0.8302\n",
      "Epoch 15/30\n",
      "626/626 - 4s - loss: 0.4272 - accuracy: 0.8016 - auc: 0.8293\n",
      "Epoch 16/30\n",
      "626/626 - 4s - loss: 0.4241 - accuracy: 0.8031 - auc: 0.8311\n",
      "Epoch 17/30\n",
      "626/626 - 4s - loss: 0.4239 - accuracy: 0.8032 - auc: 0.8317\n",
      "Epoch 18/30\n",
      "626/626 - 4s - loss: 0.4249 - accuracy: 0.8020 - auc: 0.8311\n",
      "Epoch 19/30\n",
      "626/626 - 4s - loss: 0.4218 - accuracy: 0.8062 - auc: 0.8335\n",
      "Epoch 20/30\n",
      "626/626 - 4s - loss: 0.4203 - accuracy: 0.8046 - auc: 0.8348\n",
      "Epoch 21/30\n",
      "626/626 - 4s - loss: 0.4224 - accuracy: 0.8043 - auc: 0.8323\n",
      "Epoch 22/30\n",
      "626/626 - 4s - loss: 0.4189 - accuracy: 0.8075 - auc: 0.8362\n",
      "Epoch 23/30\n",
      "626/626 - 4s - loss: 0.4210 - accuracy: 0.8052 - auc: 0.8336\n",
      "Epoch 24/30\n",
      "626/626 - 4s - loss: 0.4206 - accuracy: 0.8069 - auc: 0.8348\n",
      "Epoch 25/30\n",
      "626/626 - 4s - loss: 0.4184 - accuracy: 0.8087 - auc: 0.8363\n",
      "Epoch 26/30\n",
      "626/626 - 4s - loss: 0.4200 - accuracy: 0.8070 - auc: 0.8343\n",
      "Epoch 27/30\n",
      "626/626 - 4s - loss: 0.4186 - accuracy: 0.8086 - auc: 0.8361\n",
      "Epoch 28/30\n",
      "626/626 - 4s - loss: 0.4178 - accuracy: 0.8083 - auc: 0.8369\n",
      "Epoch 29/30\n",
      "626/626 - 4s - loss: 0.4169 - accuracy: 0.8092 - auc: 0.8373\n",
      "Epoch 30/30\n",
      "626/626 - 4s - loss: 0.4170 - accuracy: 0.8091 - auc: 0.8366\n",
      "Epoch 1/30\n",
      "626/626 - 4s - loss: 1.3804 - accuracy: 0.7075 - auc: 0.6484\n",
      "Epoch 2/30\n",
      "626/626 - 4s - loss: 0.4837 - accuracy: 0.7718 - auc: 0.7818\n",
      "Epoch 3/30\n",
      "626/626 - 4s - loss: 0.4666 - accuracy: 0.7786 - auc: 0.7974\n",
      "Epoch 4/30\n",
      "626/626 - 4s - loss: 0.4513 - accuracy: 0.7866 - auc: 0.8098\n",
      "Epoch 5/30\n",
      "626/626 - 4s - loss: 0.4521 - accuracy: 0.7877 - auc: 0.8101\n",
      "Epoch 6/30\n",
      "626/626 - 4s - loss: 0.4401 - accuracy: 0.7944 - auc: 0.8192\n",
      "Epoch 7/30\n",
      "626/626 - 4s - loss: 0.4418 - accuracy: 0.7940 - auc: 0.8189\n",
      "Epoch 8/30\n",
      "626/626 - 4s - loss: 0.4381 - accuracy: 0.7949 - auc: 0.8210\n",
      "Epoch 9/30\n",
      "626/626 - 4s - loss: 0.4394 - accuracy: 0.7945 - auc: 0.8198\n",
      "Epoch 10/30\n",
      "626/626 - 4s - loss: 0.4352 - accuracy: 0.7964 - auc: 0.8223\n",
      "Epoch 11/30\n",
      "626/626 - 4s - loss: 0.4330 - accuracy: 0.7979 - auc: 0.8247\n",
      "Epoch 12/30\n",
      "626/626 - 4s - loss: 0.4287 - accuracy: 0.8013 - auc: 0.8286\n",
      "Epoch 13/30\n",
      "626/626 - 4s - loss: 0.4277 - accuracy: 0.8024 - auc: 0.8284\n",
      "Epoch 14/30\n",
      "626/626 - 4s - loss: 0.4304 - accuracy: 0.7980 - auc: 0.8262\n",
      "Epoch 15/30\n",
      "626/626 - 4s - loss: 0.4274 - accuracy: 0.8006 - auc: 0.8284\n",
      "Epoch 16/30\n",
      "626/626 - 4s - loss: 0.4261 - accuracy: 0.8012 - auc: 0.8302\n",
      "Epoch 17/30\n",
      "626/626 - 4s - loss: 0.4229 - accuracy: 0.8059 - auc: 0.8329\n",
      "Epoch 18/30\n",
      "626/626 - 4s - loss: 0.4230 - accuracy: 0.8044 - auc: 0.8328\n",
      "Epoch 19/30\n",
      "626/626 - 4s - loss: 0.4244 - accuracy: 0.8012 - auc: 0.8315\n",
      "Epoch 20/30\n",
      "626/626 - 4s - loss: 0.4234 - accuracy: 0.8045 - auc: 0.8326\n",
      "Epoch 21/30\n",
      "626/626 - 4s - loss: 0.4230 - accuracy: 0.8046 - auc: 0.8325\n",
      "Epoch 22/30\n",
      "626/626 - 4s - loss: 0.4192 - accuracy: 0.8061 - auc: 0.8353\n",
      "Epoch 23/30\n",
      "626/626 - 4s - loss: 0.4206 - accuracy: 0.8045 - auc: 0.8345\n",
      "Epoch 24/30\n",
      "626/626 - 4s - loss: 0.4206 - accuracy: 0.8068 - auc: 0.8346\n",
      "Epoch 25/30\n",
      "626/626 - 4s - loss: 0.4180 - accuracy: 0.8088 - auc: 0.8364\n",
      "Epoch 26/30\n",
      "626/626 - 4s - loss: 0.4189 - accuracy: 0.8075 - auc: 0.8358\n",
      "Epoch 27/30\n",
      "626/626 - 4s - loss: 0.4195 - accuracy: 0.8064 - auc: 0.8355\n",
      "Epoch 28/30\n",
      "626/626 - 4s - loss: 0.4180 - accuracy: 0.8082 - auc: 0.8365\n",
      "Epoch 29/30\n",
      "626/626 - 4s - loss: 0.4179 - accuracy: 0.8086 - auc: 0.8365\n",
      "Epoch 30/30\n",
      "626/626 - 4s - loss: 0.4173 - accuracy: 0.8088 - auc: 0.8376\n",
      "Epoch 1/30\n",
      "626/626 - 4s - loss: 1.2198 - accuracy: 0.7126 - auc: 0.6616\n",
      "Epoch 2/30\n",
      "626/626 - 4s - loss: 0.4844 - accuracy: 0.7718 - auc: 0.7802\n",
      "Epoch 3/30\n",
      "626/626 - 4s - loss: 0.4660 - accuracy: 0.7796 - auc: 0.7981\n",
      "Epoch 4/30\n",
      "626/626 - 4s - loss: 0.4562 - accuracy: 0.7847 - auc: 0.8058\n",
      "Epoch 5/30\n",
      "626/626 - 4s - loss: 0.4503 - accuracy: 0.7877 - auc: 0.8115\n",
      "Epoch 6/30\n",
      "626/626 - 4s - loss: 0.4418 - accuracy: 0.7940 - auc: 0.8173\n",
      "Epoch 7/30\n",
      "626/626 - 4s - loss: 0.4385 - accuracy: 0.7957 - auc: 0.8195\n",
      "Epoch 8/30\n",
      "626/626 - 4s - loss: 0.4403 - accuracy: 0.7921 - auc: 0.8188\n",
      "Epoch 9/30\n",
      "626/626 - 4s - loss: 0.4386 - accuracy: 0.7944 - auc: 0.8193\n",
      "Epoch 10/30\n",
      "626/626 - 4s - loss: 0.4315 - accuracy: 0.7980 - auc: 0.8263\n",
      "Epoch 11/30\n",
      "626/626 - 4s - loss: 0.4291 - accuracy: 0.7997 - auc: 0.8278\n",
      "Epoch 12/30\n",
      "626/626 - 4s - loss: 0.4274 - accuracy: 0.8013 - auc: 0.8290\n",
      "Epoch 13/30\n",
      "626/626 - 4s - loss: 0.4277 - accuracy: 0.8037 - auc: 0.8285\n",
      "Epoch 14/30\n",
      "626/626 - 4s - loss: 0.4241 - accuracy: 0.8046 - auc: 0.8317\n",
      "Epoch 15/30\n",
      "626/626 - 4s - loss: 0.4252 - accuracy: 0.8030 - auc: 0.8304\n",
      "Epoch 16/30\n",
      "626/626 - 4s - loss: 0.4237 - accuracy: 0.8030 - auc: 0.8321\n",
      "Epoch 17/30\n",
      "626/626 - 4s - loss: 0.4243 - accuracy: 0.8037 - auc: 0.8310\n",
      "Epoch 18/30\n",
      "626/626 - 4s - loss: 0.4206 - accuracy: 0.8052 - auc: 0.8344\n",
      "Epoch 19/30\n",
      "626/626 - 4s - loss: 0.4221 - accuracy: 0.8065 - auc: 0.8334\n",
      "Epoch 20/30\n",
      "626/626 - 4s - loss: 0.4229 - accuracy: 0.8043 - auc: 0.8327\n",
      "Epoch 21/30\n",
      "626/626 - 4s - loss: 0.4206 - accuracy: 0.8059 - auc: 0.8348\n",
      "Epoch 22/30\n",
      "626/626 - 4s - loss: 0.4221 - accuracy: 0.8042 - auc: 0.8334\n",
      "Epoch 23/30\n",
      "626/626 - 4s - loss: 0.4208 - accuracy: 0.8056 - auc: 0.8334\n",
      "Epoch 24/30\n",
      "626/626 - 4s - loss: 0.4187 - accuracy: 0.8092 - auc: 0.8361\n",
      "Epoch 25/30\n",
      "626/626 - 4s - loss: 0.4198 - accuracy: 0.8048 - auc: 0.8352\n",
      "Epoch 26/30\n",
      "626/626 - 4s - loss: 0.4172 - accuracy: 0.8081 - auc: 0.8366\n",
      "Epoch 27/30\n",
      "626/626 - 4s - loss: 0.4193 - accuracy: 0.8077 - auc: 0.8349\n",
      "Epoch 28/30\n",
      "626/626 - 4s - loss: 0.4190 - accuracy: 0.8070 - auc: 0.8352\n",
      "Epoch 29/30\n",
      "626/626 - 4s - loss: 0.4189 - accuracy: 0.8063 - auc: 0.8357\n",
      "Epoch 30/30\n",
      "626/626 - 4s - loss: 0.4169 - accuracy: 0.8096 - auc: 0.8371\n",
      "Epoch 1/30\n",
      "626/626 - 4s - loss: 1.1738 - accuracy: 0.7146 - auc: 0.6586\n",
      "Epoch 2/30\n",
      "626/626 - 4s - loss: 0.4862 - accuracy: 0.7708 - auc: 0.7770\n",
      "Epoch 3/30\n",
      "626/626 - 4s - loss: 0.4627 - accuracy: 0.7827 - auc: 0.8005\n",
      "Epoch 4/30\n",
      "626/626 - 4s - loss: 0.4524 - accuracy: 0.7875 - auc: 0.8080\n",
      "Epoch 5/30\n",
      "626/626 - 4s - loss: 0.4519 - accuracy: 0.7884 - auc: 0.8098\n",
      "Epoch 6/30\n",
      "626/626 - 4s - loss: 0.4445 - accuracy: 0.7916 - auc: 0.8151\n",
      "Epoch 7/30\n",
      "626/626 - 4s - loss: 0.4406 - accuracy: 0.7938 - auc: 0.8187\n",
      "Epoch 8/30\n",
      "626/626 - 4s - loss: 0.4411 - accuracy: 0.7929 - auc: 0.8188\n",
      "Epoch 9/30\n",
      "626/626 - 4s - loss: 0.4325 - accuracy: 0.7973 - auc: 0.8250\n",
      "Epoch 10/30\n",
      "626/626 - 4s - loss: 0.4271 - accuracy: 0.8015 - auc: 0.8294\n",
      "Epoch 11/30\n",
      "626/626 - 4s - loss: 0.4320 - accuracy: 0.7984 - auc: 0.8250\n",
      "Epoch 12/30\n",
      "626/626 - 4s - loss: 0.4314 - accuracy: 0.7984 - auc: 0.8254\n",
      "Epoch 13/30\n",
      "626/626 - 4s - loss: 0.4272 - accuracy: 0.8018 - auc: 0.8286\n",
      "Epoch 14/30\n",
      "626/626 - 4s - loss: 0.4249 - accuracy: 0.8031 - auc: 0.8310\n",
      "Epoch 15/30\n",
      "626/626 - 4s - loss: 0.4232 - accuracy: 0.8050 - auc: 0.8330\n",
      "Epoch 16/30\n",
      "626/626 - 4s - loss: 0.4244 - accuracy: 0.8031 - auc: 0.8315\n",
      "Epoch 17/30\n",
      "626/626 - 4s - loss: 0.4222 - accuracy: 0.8061 - auc: 0.8335\n",
      "Epoch 18/30\n",
      "626/626 - 4s - loss: 0.4225 - accuracy: 0.8056 - auc: 0.8331\n",
      "Epoch 19/30\n",
      "626/626 - 4s - loss: 0.4213 - accuracy: 0.8062 - auc: 0.8349\n",
      "Epoch 20/30\n",
      "626/626 - 4s - loss: 0.4197 - accuracy: 0.8062 - auc: 0.8354\n",
      "Epoch 21/30\n",
      "626/626 - 4s - loss: 0.4207 - accuracy: 0.8068 - auc: 0.8339\n",
      "Epoch 22/30\n",
      "626/626 - 4s - loss: 0.4202 - accuracy: 0.8059 - auc: 0.8347\n",
      "Epoch 23/30\n",
      "626/626 - 4s - loss: 0.4227 - accuracy: 0.8051 - auc: 0.8321\n",
      "Epoch 24/30\n",
      "626/626 - 4s - loss: 0.4196 - accuracy: 0.8052 - auc: 0.8353\n",
      "Epoch 25/30\n",
      "626/626 - 4s - loss: 0.4180 - accuracy: 0.8086 - auc: 0.8366\n",
      "Epoch 26/30\n",
      "626/626 - 4s - loss: 0.4193 - accuracy: 0.8075 - auc: 0.8353\n",
      "Epoch 27/30\n",
      "626/626 - 4s - loss: 0.4178 - accuracy: 0.8079 - auc: 0.8358\n",
      "Epoch 28/30\n",
      "626/626 - 4s - loss: 0.4182 - accuracy: 0.8071 - auc: 0.8360\n",
      "Epoch 29/30\n",
      "626/626 - 4s - loss: 0.4174 - accuracy: 0.8084 - auc: 0.8370\n",
      "Epoch 30/30\n",
      "626/626 - 4s - loss: 0.4162 - accuracy: 0.8072 - auc: 0.8379\n"
     ]
    }
   ],
   "source": [
    "# 10 fold\n",
    "kfolds = 10 # \n",
    "split = KFold(n_splits=kfolds, shuffle=True, random_state=42)\n",
    "\n",
    "x = data_cln.drop([\"is_canceled\"], axis=1)[features]\n",
    "y = data_cln[\"is_canceled\"].to_numpy()\n",
    "\n",
    "x = preprocessor.fit_transform(x)\n",
    "\n",
    "train_x = x[data_cln.hotel == 'Resort Hotel']\n",
    "train_y = y[data_cln.hotel == 'Resort Hotel']\n",
    "\n",
    "test_x = x[data_cln.hotel == 'City Hotel']\n",
    "test_y = y[data_cln.hotel == 'City Hotel']\n",
    "result = []\n",
    "\n",
    "for i in range(10):\n",
    "    model = test_model_1()\n",
    "    \n",
    "    history = model.fit(train_x, train_y, batch_size=64, epochs=30, verbose = 2)\n",
    "    pred_y = model.predict(test_x)\n",
    "    result.append({'pred': pred_y, 'test': test_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_accuracy = []\n",
    "total_f1 = []\n",
    "total_pre = []\n",
    "total_recall = []\n",
    "total_auc = []\n",
    "for i in range(10):\n",
    "    pred = result[i]['pred']\n",
    "    test = result[i]['test']\n",
    "    fpr, tpr, _ = roc_curve(test, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    total_auc.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=0.8)\n",
    "    t_acc = []\n",
    "    t_f1 = []\n",
    "    t_pre = []\n",
    "    t_rec = []\n",
    "    for t in np.arange(0,1,0.05):\n",
    "        p_val = np.zeros(pred.shape)\n",
    "        p_val[pred > t] = 1\n",
    "        t_acc.append(accuracy_score(test, p_val))\n",
    "        t_f1.append(f1_score(test, p_val))\n",
    "        t_pre.append(precision_score(test, p_val))\n",
    "        t_rec.append(recall_score(test, p_val)) \n",
    "    total_accuracy.append(np.max(t_acc))\n",
    "    total_f1.append(np.max(t_f1))\n",
    "    total_pre.append(np.max(t_pre))\n",
    "    total_recall.append(np.max(t_rec)) \n",
    "    \n",
    "plt.savefig('rcDNN.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_res = {'auc':total_auc, 'acc': total_accuracy, 'f1': total_f1,\n",
    "            'pre': total_pre, 'recall': total_recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc \t 0.8369532568049608 0.8407503764234892 0.8392686996588198\n",
      "acc \t 0.7891592083700996 0.7944787596117484 0.7917093155174587\n",
      "f1 \t 0.7205490019607212 0.7270657792813443 0.72515000675429\n",
      "pre \t 0.996097649514475 0.9965721929604549 0.9963936051981568\n",
      "recall \t 1.0 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# total\n",
    "for k, v in total_res.items():\n",
    "    print(k, '\\t', min(v), max(v), np.average(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': [0.8392211230790696,\n",
       "  0.8403085484561637,\n",
       "  0.8390436540990163,\n",
       "  0.8390786319626349,\n",
       "  0.8370409702128305,\n",
       "  0.84050980129868,\n",
       "  0.8407503764234892,\n",
       "  0.8393982022507988,\n",
       "  0.8369532568049608,\n",
       "  0.8403824320005552],\n",
       " 'acc': [0.7900794151014748,\n",
       "  0.7925375015756965,\n",
       "  0.7936215807386865,\n",
       "  0.7919702508508761,\n",
       "  0.7901550485314509,\n",
       "  0.7924996848607084,\n",
       "  0.7944787596117484,\n",
       "  0.7906718769696206,\n",
       "  0.7891592083700996,\n",
       "  0.7919198285642254],\n",
       " 'f1': [0.726083199604987,\n",
       "  0.7269770213040048,\n",
       "  0.7243720298710116,\n",
       "  0.7244253195335372,\n",
       "  0.7205490019607212,\n",
       "  0.7270496698897482,\n",
       "  0.7262383668567998,\n",
       "  0.7262117647058822,\n",
       "  0.722527914534865,\n",
       "  0.7270657792813443],\n",
       " 'pre': [0.9965721929604549,\n",
       "  0.9964154851043492,\n",
       "  0.9964785708150821,\n",
       "  0.9963690899044912,\n",
       "  0.9961832061068703,\n",
       "  0.9965220415616033,\n",
       "  0.9963361016121153,\n",
       "  0.9965715265278134,\n",
       "  0.996097649514475,\n",
       "  0.9963901878743129],\n",
       " 'recall': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8392686996588198"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(total_res['auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7917093155174587"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(total_res['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
