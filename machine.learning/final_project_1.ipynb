{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_validate, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('hotel_bookings.csv')\n",
    "data_cln = data.fillna({'children': 0.0, 'country': 'Unknown', 'agent':0, 'company': 0})\n",
    "data_cln['meal'].replace('Undefined', 'SC', inplace = True)\n",
    "\n",
    "num_features = [\"lead_time\",\"arrival_date_week_number\",\"arrival_date_day_of_month\",\n",
    "                \"stays_in_weekend_nights\",\"stays_in_week_nights\",\"adults\",\"children\",\n",
    "                \"babies\",\"is_repeated_guest\", \"previous_cancellations\",\n",
    "                \"previous_bookings_not_canceled\",\"agent\",\"company\",\n",
    "                \"required_car_parking_spaces\", \"total_of_special_requests\", \"adr\"]\n",
    "\n",
    "cat_features = [\"arrival_date_month\",\"meal\",\"market_segment\",\n",
    "                \"distribution_channel\",\"reserved_room_type\",\"deposit_type\",\"customer_type\"]\n",
    "\n",
    "# Separate features and predicted value\n",
    "features = num_features + cat_features\n",
    "\n",
    "# preprocess numerical feats:\n",
    "# for most num cols, except the dates, 0 is the most logical choice as fill value\n",
    "# and here no dates are missing.\n",
    "num_transformer = SimpleImputer(strategy=\"constant\")\n",
    "\n",
    "# Preprocessing for categorical features:\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical features:\n",
    "preprocessor = ColumnTransformer(transformers=[(\"num\", num_transformer, num_features),\n",
    "                                               (\"cat\", cat_transformer, cat_features)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_1():\n",
    "    inputs = keras.Input(shape=(62,), dtype = \"float32\")\n",
    "    \n",
    "    x = layers.Dense(256)(inputs)\n",
    "#     x = layers.Dense(256)(x)\n",
    "#     x = layers.Dense(256)(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = layers.Dense(64)(x)\n",
    "    x = layers.Dense(32)(x)\n",
    "    x = layers.Dense(16)(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid',\n",
    "                    kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4))(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    # model.summary()\n",
    "\n",
    "    model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\", \"AUC\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kfolds = 10 \n",
    "# kf = KFold(n_splits=kfolds, shuffle=True, random_state=42)\n",
    "# accuracy_res = []\n",
    "# pred_res = []\n",
    "# for train_index, test_index in kf.split(y):\n",
    "#     train_x = X[train_index]\n",
    "#     train_y = y[train_index]\n",
    "    \n",
    "#     test_x = X[test_index]\n",
    "#     test_y = y[test_index]\n",
    "    \n",
    "#     model = test_model_1()\n",
    "    \n",
    "#     history = model.fit(train_x, train_y, batch_size=64, epochs=30, )\n",
    "#     pred_y = model.predict(test_x)\n",
    "#     pred_res.append({'pred': pred_y, 'real': test_y})\n",
    "#     tmp = []\n",
    "#     for i in np.arange(0, 1, 0.01):\n",
    "#         tmp_y = np.zeros(pred_y.shape)\n",
    "#         tmp_y[pred_y > i] = 1\n",
    "#         tmp.append(accuracy_score(test_y, tmp_y))\n",
    "#     print(max(tmp))\n",
    "#     accuracy_res.append(max(tmp))\n",
    "        \n",
    "# accuracy_val = np.array(accuracy_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1679/1679 - 10s - loss: 0.7026 - accuracy: 0.7452 - auc: 0.7692\n",
      "Epoch 2/30\n",
      "1679/1679 - 9s - loss: 0.4695 - accuracy: 0.7806 - auc: 0.8245\n",
      "Epoch 3/30\n",
      "1679/1679 - 10s - loss: 0.4576 - accuracy: 0.7889 - auc: 0.8317\n",
      "Epoch 4/30\n",
      "1679/1679 - 9s - loss: 0.4524 - accuracy: 0.7920 - auc: 0.8345\n",
      "Epoch 5/30\n",
      "1679/1679 - 9s - loss: 0.4509 - accuracy: 0.7919 - auc: 0.8359\n",
      "Epoch 6/30\n",
      "1679/1679 - 9s - loss: 0.4473 - accuracy: 0.7947 - auc: 0.8384\n",
      "Epoch 7/30\n",
      "1679/1679 - 10s - loss: 0.4457 - accuracy: 0.7960 - auc: 0.8396\n",
      "Epoch 8/30\n",
      "1679/1679 - 10s - loss: 0.4442 - accuracy: 0.7952 - auc: 0.8404\n",
      "Epoch 9/30\n",
      "1679/1679 - 11s - loss: 0.4431 - accuracy: 0.7980 - auc: 0.8414\n",
      "Epoch 10/30\n",
      "1679/1679 - 11s - loss: 0.4428 - accuracy: 0.7981 - auc: 0.8413\n",
      "Epoch 11/30\n",
      "1679/1679 - 8s - loss: 0.4407 - accuracy: 0.7985 - auc: 0.8432\n",
      "Epoch 12/30\n",
      "1679/1679 - 9s - loss: 0.4401 - accuracy: 0.8004 - auc: 0.8435\n",
      "Epoch 13/30\n",
      "1679/1679 - 9s - loss: 0.4398 - accuracy: 0.8010 - auc: 0.8439\n",
      "Epoch 14/30\n",
      "1679/1679 - 9s - loss: 0.4396 - accuracy: 0.8020 - auc: 0.8441\n",
      "Epoch 15/30\n",
      "1679/1679 - 10s - loss: 0.4395 - accuracy: 0.8011 - auc: 0.8442\n",
      "Epoch 16/30\n",
      "1679/1679 - 10s - loss: 0.4391 - accuracy: 0.8008 - auc: 0.8441\n",
      "Epoch 17/30\n",
      "1679/1679 - 10s - loss: 0.4382 - accuracy: 0.8028 - auc: 0.8452\n",
      "Epoch 18/30\n",
      "1679/1679 - 10s - loss: 0.4388 - accuracy: 0.8018 - auc: 0.8445\n",
      "Epoch 19/30\n",
      "1679/1679 - 11s - loss: 0.4377 - accuracy: 0.8024 - auc: 0.8455\n",
      "Epoch 20/30\n",
      "1679/1679 - 12s - loss: 0.4373 - accuracy: 0.8030 - auc: 0.8458\n",
      "Epoch 21/30\n",
      "1679/1679 - 12s - loss: 0.4373 - accuracy: 0.8035 - auc: 0.8458\n",
      "Epoch 22/30\n",
      "1679/1679 - 12s - loss: 0.4378 - accuracy: 0.8021 - auc: 0.8453\n",
      "Epoch 23/30\n",
      "1679/1679 - 12s - loss: 0.4374 - accuracy: 0.8033 - auc: 0.8458\n",
      "Epoch 24/30\n",
      "1679/1679 - 12s - loss: 0.4371 - accuracy: 0.8018 - auc: 0.8460\n",
      "Epoch 25/30\n",
      "1679/1679 - 12s - loss: 0.4378 - accuracy: 0.8025 - auc: 0.8455\n",
      "Epoch 26/30\n",
      "1679/1679 - 12s - loss: 0.4375 - accuracy: 0.8030 - auc: 0.8454\n",
      "Epoch 27/30\n",
      "1679/1679 - 11s - loss: 0.4369 - accuracy: 0.8035 - auc: 0.8466\n",
      "Epoch 28/30\n",
      "1679/1679 - 12s - loss: 0.4369 - accuracy: 0.8036 - auc: 0.8461\n",
      "Epoch 29/30\n",
      "1679/1679 - 11s - loss: 0.4369 - accuracy: 0.8034 - auc: 0.8462\n",
      "Epoch 30/30\n",
      "1679/1679 - 12s - loss: 0.4371 - accuracy: 0.8039 - auc: 0.8459\n",
      "Epoch 1/30\n",
      "1679/1679 - 12s - loss: 0.7333 - accuracy: 0.7428 - auc: 0.7659\n",
      "Epoch 2/30\n",
      "1679/1679 - 12s - loss: 0.4733 - accuracy: 0.7788 - auc: 0.8222\n",
      "Epoch 3/30\n",
      "1679/1679 - 12s - loss: 0.4653 - accuracy: 0.7830 - auc: 0.8265\n",
      "Epoch 4/30\n",
      "1679/1679 - 12s - loss: 0.4570 - accuracy: 0.7898 - auc: 0.8329\n",
      "Epoch 5/30\n",
      "1679/1679 - 12s - loss: 0.4500 - accuracy: 0.7926 - auc: 0.8369\n",
      "Epoch 6/30\n",
      "1679/1679 - 12s - loss: 0.4470 - accuracy: 0.7946 - auc: 0.8387\n",
      "Epoch 7/30\n",
      "1679/1679 - 12s - loss: 0.4462 - accuracy: 0.7956 - auc: 0.8395\n",
      "Epoch 8/30\n",
      "1679/1679 - 12s - loss: 0.4457 - accuracy: 0.7967 - auc: 0.8397\n",
      "Epoch 9/30\n",
      "1679/1679 - 11s - loss: 0.4420 - accuracy: 0.7992 - auc: 0.8428\n",
      "Epoch 10/30\n",
      "1679/1679 - 12s - loss: 0.4413 - accuracy: 0.7993 - auc: 0.8433\n",
      "Epoch 11/30\n",
      "1679/1679 - 12s - loss: 0.4400 - accuracy: 0.8009 - auc: 0.8440\n",
      "Epoch 12/30\n",
      "1679/1679 - 12s - loss: 0.4397 - accuracy: 0.8006 - auc: 0.8443\n",
      "Epoch 13/30\n",
      "1679/1679 - 11s - loss: 0.4398 - accuracy: 0.8013 - auc: 0.8441\n",
      "Epoch 14/30\n",
      "1679/1679 - 12s - loss: 0.4391 - accuracy: 0.8019 - auc: 0.8451\n",
      "Epoch 15/30\n",
      "1679/1679 - 12s - loss: 0.4385 - accuracy: 0.8023 - auc: 0.8455\n",
      "Epoch 16/30\n",
      "1679/1679 - 12s - loss: 0.4381 - accuracy: 0.8035 - auc: 0.8457\n",
      "Epoch 17/30\n",
      "1679/1679 - 12s - loss: 0.4377 - accuracy: 0.8039 - auc: 0.8459\n",
      "Epoch 18/30\n",
      "1679/1679 - 12s - loss: 0.4374 - accuracy: 0.8026 - auc: 0.8461\n",
      "Epoch 19/30\n",
      "1679/1679 - 12s - loss: 0.4373 - accuracy: 0.8033 - auc: 0.8462\n",
      "Epoch 20/30\n",
      "1679/1679 - 11s - loss: 0.4368 - accuracy: 0.8038 - auc: 0.8467\n",
      "Epoch 21/30\n",
      "1679/1679 - 11s - loss: 0.4373 - accuracy: 0.8030 - auc: 0.8463\n",
      "Epoch 22/30\n",
      "1679/1679 - 12s - loss: 0.4374 - accuracy: 0.8037 - auc: 0.8461\n",
      "Epoch 23/30\n",
      "1679/1679 - 12s - loss: 0.4379 - accuracy: 0.8034 - auc: 0.8460\n",
      "Epoch 24/30\n",
      "1679/1679 - 11s - loss: 0.4369 - accuracy: 0.8041 - auc: 0.8467\n",
      "Epoch 25/30\n",
      "1679/1679 - 12s - loss: 0.4366 - accuracy: 0.8042 - auc: 0.8468\n",
      "Epoch 26/30\n",
      "1679/1679 - 12s - loss: 0.4369 - accuracy: 0.8038 - auc: 0.8465\n",
      "Epoch 27/30\n",
      "1679/1679 - 12s - loss: 0.4369 - accuracy: 0.8042 - auc: 0.8465\n",
      "Epoch 28/30\n",
      "1679/1679 - 12s - loss: 0.4372 - accuracy: 0.8034 - auc: 0.8465\n",
      "Epoch 29/30\n",
      "1679/1679 - 12s - loss: 0.4363 - accuracy: 0.8048 - auc: 0.8470\n",
      "Epoch 30/30\n",
      "1679/1679 - 12s - loss: 0.4357 - accuracy: 0.8054 - auc: 0.8477\n",
      "Epoch 1/30\n",
      "1679/1679 - 12s - loss: 0.7032 - accuracy: 0.7449 - auc: 0.7695\n",
      "Epoch 2/30\n",
      "1679/1679 - 11s - loss: 0.4709 - accuracy: 0.7805 - auc: 0.8239\n",
      "Epoch 3/30\n",
      "1679/1679 - 12s - loss: 0.4605 - accuracy: 0.7851 - auc: 0.8300\n",
      "Epoch 4/30\n",
      "1679/1679 - 12s - loss: 0.4514 - accuracy: 0.7907 - auc: 0.8358\n",
      "Epoch 5/30\n",
      "1679/1679 - 11s - loss: 0.4498 - accuracy: 0.7929 - auc: 0.8367\n",
      "Epoch 6/30\n",
      "1679/1679 - 12s - loss: 0.4458 - accuracy: 0.7955 - auc: 0.8399\n",
      "Epoch 7/30\n",
      "1679/1679 - 12s - loss: 0.4458 - accuracy: 0.7961 - auc: 0.8402\n",
      "Epoch 8/30\n",
      "1679/1679 - 12s - loss: 0.4429 - accuracy: 0.7976 - auc: 0.8418\n",
      "Epoch 9/30\n",
      "1679/1679 - 12s - loss: 0.4415 - accuracy: 0.7976 - auc: 0.8429\n",
      "Epoch 10/30\n",
      "1679/1679 - 11s - loss: 0.4419 - accuracy: 0.7985 - auc: 0.8425\n",
      "Epoch 11/30\n",
      "1679/1679 - 12s - loss: 0.4397 - accuracy: 0.8008 - auc: 0.8445\n",
      "Epoch 12/30\n",
      "1679/1679 - 12s - loss: 0.4397 - accuracy: 0.8002 - auc: 0.8444\n",
      "Epoch 13/30\n",
      "1679/1679 - 12s - loss: 0.4391 - accuracy: 0.8003 - auc: 0.8449\n",
      "Epoch 14/30\n",
      "1679/1679 - 11s - loss: 0.4390 - accuracy: 0.8012 - auc: 0.8448\n",
      "Epoch 15/30\n",
      "1679/1679 - 12s - loss: 0.4379 - accuracy: 0.8022 - auc: 0.8460\n",
      "Epoch 16/30\n",
      "1679/1679 - 12s - loss: 0.4387 - accuracy: 0.8005 - auc: 0.8454\n",
      "Epoch 17/30\n",
      "1679/1679 - 12s - loss: 0.4379 - accuracy: 0.8015 - auc: 0.8460\n",
      "Epoch 18/30\n",
      "1679/1679 - 12s - loss: 0.4367 - accuracy: 0.8025 - auc: 0.8466\n",
      "Epoch 19/30\n",
      "1679/1679 - 12s - loss: 0.4372 - accuracy: 0.8029 - auc: 0.8464\n",
      "Epoch 20/30\n",
      "1679/1679 - 12s - loss: 0.4373 - accuracy: 0.8018 - auc: 0.8461\n",
      "Epoch 21/30\n",
      "1679/1679 - 11s - loss: 0.4376 - accuracy: 0.8024 - auc: 0.8460\n",
      "Epoch 22/30\n",
      "1679/1679 - 12s - loss: 0.4361 - accuracy: 0.8027 - auc: 0.8474\n",
      "Epoch 23/30\n",
      "1679/1679 - 12s - loss: 0.4371 - accuracy: 0.8030 - auc: 0.8464\n",
      "Epoch 24/30\n",
      "1679/1679 - 12s - loss: 0.4364 - accuracy: 0.8037 - auc: 0.8469\n",
      "Epoch 25/30\n",
      "1679/1679 - 12s - loss: 0.4361 - accuracy: 0.8034 - auc: 0.8469\n",
      "Epoch 26/30\n",
      "1679/1679 - 11s - loss: 0.4369 - accuracy: 0.8023 - auc: 0.8468\n",
      "Epoch 27/30\n",
      "1679/1679 - 12s - loss: 0.4365 - accuracy: 0.8040 - auc: 0.8468\n",
      "Epoch 28/30\n",
      "1679/1679 - 11s - loss: 0.4362 - accuracy: 0.8034 - auc: 0.8472\n",
      "Epoch 29/30\n",
      "1679/1679 - 12s - loss: 0.4364 - accuracy: 0.8035 - auc: 0.8471\n",
      "Epoch 30/30\n",
      "1679/1679 - 12s - loss: 0.4358 - accuracy: 0.8040 - auc: 0.8474\n",
      "Epoch 1/30\n",
      "1679/1679 - 12s - loss: 0.6841 - accuracy: 0.7476 - auc: 0.7698\n",
      "Epoch 2/30\n",
      "1679/1679 - 12s - loss: 0.4689 - accuracy: 0.7815 - auc: 0.8252\n",
      "Epoch 3/30\n",
      "1679/1679 - 12s - loss: 0.4581 - accuracy: 0.7863 - auc: 0.8310\n",
      "Epoch 4/30\n",
      "1679/1679 - 12s - loss: 0.4543 - accuracy: 0.7887 - auc: 0.8334\n",
      "Epoch 5/30\n",
      "1679/1679 - 12s - loss: 0.4476 - accuracy: 0.7934 - auc: 0.8384\n",
      "Epoch 6/30\n",
      "1679/1679 - 12s - loss: 0.4466 - accuracy: 0.7944 - auc: 0.8397\n",
      "Epoch 7/30\n",
      "1679/1679 - 11s - loss: 0.4446 - accuracy: 0.7964 - auc: 0.8410\n",
      "Epoch 8/30\n",
      "1679/1679 - 12s - loss: 0.4419 - accuracy: 0.7980 - auc: 0.8425\n",
      "Epoch 9/30\n",
      "1679/1679 - 12s - loss: 0.4414 - accuracy: 0.7992 - auc: 0.8427\n",
      "Epoch 10/30\n",
      "1679/1679 - 12s - loss: 0.4410 - accuracy: 0.7994 - auc: 0.8433\n",
      "Epoch 11/30\n",
      "1679/1679 - 12s - loss: 0.4404 - accuracy: 0.8000 - auc: 0.8433\n",
      "Epoch 12/30\n",
      "1679/1679 - 12s - loss: 0.4392 - accuracy: 0.8009 - auc: 0.8448\n",
      "Epoch 13/30\n",
      "1679/1679 - 12s - loss: 0.4389 - accuracy: 0.8010 - auc: 0.8445\n",
      "Epoch 14/30\n",
      "1679/1679 - 12s - loss: 0.4386 - accuracy: 0.8020 - auc: 0.8452\n",
      "Epoch 15/30\n",
      "1679/1679 - 12s - loss: 0.4383 - accuracy: 0.8019 - auc: 0.8454\n",
      "Epoch 16/30\n",
      "1679/1679 - 12s - loss: 0.4376 - accuracy: 0.8029 - auc: 0.8457\n",
      "Epoch 17/30\n",
      "1679/1679 - 12s - loss: 0.4379 - accuracy: 0.8023 - auc: 0.8458\n",
      "Epoch 18/30\n",
      "1679/1679 - 12s - loss: 0.4385 - accuracy: 0.8020 - auc: 0.8451\n",
      "Epoch 19/30\n",
      "1679/1679 - 11s - loss: 0.4374 - accuracy: 0.8025 - auc: 0.8460\n",
      "Epoch 20/30\n",
      "1679/1679 - 12s - loss: 0.4366 - accuracy: 0.8025 - auc: 0.8465\n",
      "Epoch 21/30\n",
      "1679/1679 - 11s - loss: 0.4371 - accuracy: 0.8023 - auc: 0.8460\n",
      "Epoch 22/30\n",
      "1679/1679 - 11s - loss: 0.4369 - accuracy: 0.8030 - auc: 0.8466\n",
      "Epoch 23/30\n",
      "1679/1679 - 10s - loss: 0.4372 - accuracy: 0.8034 - auc: 0.8464\n",
      "Epoch 24/30\n",
      "1679/1679 - 10s - loss: 0.4366 - accuracy: 0.8033 - auc: 0.8467\n",
      "Epoch 25/30\n",
      "1679/1679 - 10s - loss: 0.4368 - accuracy: 0.8033 - auc: 0.8468\n",
      "Epoch 26/30\n",
      "1679/1679 - 11s - loss: 0.4365 - accuracy: 0.8031 - auc: 0.8471\n",
      "Epoch 27/30\n",
      "1679/1679 - 10s - loss: 0.4362 - accuracy: 0.8031 - auc: 0.8472\n",
      "Epoch 28/30\n",
      "1679/1679 - 10s - loss: 0.4357 - accuracy: 0.8038 - auc: 0.8475\n",
      "Epoch 29/30\n",
      "1679/1679 - 11s - loss: 0.4364 - accuracy: 0.8028 - auc: 0.8467\n",
      "Epoch 30/30\n",
      "1679/1679 - 10s - loss: 0.4359 - accuracy: 0.8039 - auc: 0.8474\n",
      "Epoch 1/30\n",
      "1679/1679 - 10s - loss: 0.6782 - accuracy: 0.7462 - auc: 0.7726\n",
      "Epoch 2/30\n",
      "1679/1679 - 10s - loss: 0.4690 - accuracy: 0.7801 - auc: 0.8248\n",
      "Epoch 3/30\n",
      "1679/1679 - 10s - loss: 0.4613 - accuracy: 0.7857 - auc: 0.8301\n",
      "Epoch 4/30\n",
      "1679/1679 - 11s - loss: 0.4543 - accuracy: 0.7896 - auc: 0.8341\n",
      "Epoch 5/30\n",
      "1679/1679 - 10s - loss: 0.4497 - accuracy: 0.7926 - auc: 0.8370\n",
      "Epoch 6/30\n",
      "1679/1679 - 10s - loss: 0.4465 - accuracy: 0.7949 - auc: 0.8394\n",
      "Epoch 7/30\n",
      "1679/1679 - 11s - loss: 0.4440 - accuracy: 0.7980 - auc: 0.8411\n",
      "Epoch 8/30\n",
      "1679/1679 - 10s - loss: 0.4428 - accuracy: 0.7986 - auc: 0.8423\n",
      "Epoch 9/30\n",
      "1679/1679 - 10s - loss: 0.4425 - accuracy: 0.7978 - auc: 0.8424\n",
      "Epoch 10/30\n",
      "1679/1679 - 10s - loss: 0.4413 - accuracy: 0.8003 - auc: 0.8434\n",
      "Epoch 11/30\n",
      "1679/1679 - 10s - loss: 0.4403 - accuracy: 0.8011 - auc: 0.8439\n",
      "Epoch 12/30\n",
      "1679/1679 - 9s - loss: 0.4391 - accuracy: 0.8014 - auc: 0.8450\n",
      "Epoch 13/30\n",
      "1679/1679 - 9s - loss: 0.4400 - accuracy: 0.8008 - auc: 0.8442\n",
      "Epoch 14/30\n",
      "1679/1679 - 9s - loss: 0.4386 - accuracy: 0.8016 - auc: 0.8457\n",
      "Epoch 15/30\n",
      "1679/1679 - 9s - loss: 0.4377 - accuracy: 0.8027 - auc: 0.8461\n",
      "Epoch 16/30\n",
      "1679/1679 - 10s - loss: 0.4380 - accuracy: 0.8028 - auc: 0.8458\n",
      "Epoch 17/30\n",
      "1679/1679 - 9s - loss: 0.4374 - accuracy: 0.8029 - auc: 0.8464\n",
      "Epoch 18/30\n",
      "1679/1679 - 9s - loss: 0.4370 - accuracy: 0.8032 - auc: 0.8465\n",
      "Epoch 19/30\n",
      "1679/1679 - 11s - loss: 0.4372 - accuracy: 0.8034 - auc: 0.8463\n",
      "Epoch 20/30\n",
      "1679/1679 - 12s - loss: 0.4367 - accuracy: 0.8040 - auc: 0.8468\n",
      "Epoch 21/30\n",
      "1679/1679 - 11s - loss: 0.4369 - accuracy: 0.8034 - auc: 0.8466\n",
      "Epoch 22/30\n",
      "1679/1679 - 11s - loss: 0.4368 - accuracy: 0.8031 - auc: 0.8467\n",
      "Epoch 23/30\n",
      "1679/1679 - 11s - loss: 0.4366 - accuracy: 0.8046 - auc: 0.8471\n",
      "Epoch 24/30\n",
      "1679/1679 - 11s - loss: 0.4377 - accuracy: 0.8024 - auc: 0.8462\n",
      "Epoch 25/30\n",
      "1679/1679 - 11s - loss: 0.4366 - accuracy: 0.8040 - auc: 0.8469\n",
      "Epoch 26/30\n",
      "1679/1679 - 11s - loss: 0.4364 - accuracy: 0.8037 - auc: 0.8472\n",
      "Epoch 27/30\n",
      "1679/1679 - 11s - loss: 0.4366 - accuracy: 0.8033 - auc: 0.8469\n",
      "Epoch 28/30\n",
      "1679/1679 - 11s - loss: 0.4366 - accuracy: 0.8044 - auc: 0.8472\n",
      "Epoch 29/30\n",
      "1679/1679 - 11s - loss: 0.4361 - accuracy: 0.8034 - auc: 0.8472\n",
      "Epoch 30/30\n",
      "1679/1679 - 11s - loss: 0.4363 - accuracy: 0.8036 - auc: 0.8471\n",
      "Epoch 1/30\n",
      "1679/1679 - 12s - loss: 0.6358 - accuracy: 0.7475 - auc: 0.7769\n",
      "Epoch 2/30\n",
      "1679/1679 - 12s - loss: 0.4679 - accuracy: 0.7820 - auc: 0.8252\n",
      "Epoch 3/30\n",
      "1679/1679 - 11s - loss: 0.4576 - accuracy: 0.7881 - auc: 0.8318\n",
      "Epoch 4/30\n",
      "1679/1679 - 11s - loss: 0.4515 - accuracy: 0.7910 - auc: 0.8353\n",
      "Epoch 5/30\n",
      "1679/1679 - 11s - loss: 0.4486 - accuracy: 0.7940 - auc: 0.8376\n",
      "Epoch 6/30\n",
      "1679/1679 - 11s - loss: 0.4449 - accuracy: 0.7959 - auc: 0.8406\n",
      "Epoch 7/30\n",
      "1679/1679 - 12s - loss: 0.4442 - accuracy: 0.7977 - auc: 0.8413\n",
      "Epoch 8/30\n",
      "1679/1679 - 11s - loss: 0.4436 - accuracy: 0.7976 - auc: 0.8413\n",
      "Epoch 9/30\n",
      "1679/1679 - 12s - loss: 0.4431 - accuracy: 0.7969 - auc: 0.8420\n",
      "Epoch 10/30\n",
      "1679/1679 - 11s - loss: 0.4418 - accuracy: 0.7993 - auc: 0.8426\n",
      "Epoch 11/30\n",
      "1679/1679 - 11s - loss: 0.4401 - accuracy: 0.8001 - auc: 0.8442\n",
      "Epoch 12/30\n",
      "1679/1679 - 11s - loss: 0.4401 - accuracy: 0.8013 - auc: 0.8441\n",
      "Epoch 13/30\n",
      "1679/1679 - 12s - loss: 0.4395 - accuracy: 0.8007 - auc: 0.8445\n",
      "Epoch 14/30\n",
      "1679/1679 - 11s - loss: 0.4394 - accuracy: 0.8015 - auc: 0.8445\n",
      "Epoch 15/30\n",
      "1679/1679 - 12s - loss: 0.4389 - accuracy: 0.8009 - auc: 0.8448\n",
      "Epoch 16/30\n",
      "1679/1679 - 11s - loss: 0.4384 - accuracy: 0.8029 - auc: 0.8452\n",
      "Epoch 17/30\n",
      "1679/1679 - 11s - loss: 0.4383 - accuracy: 0.8021 - auc: 0.8455\n",
      "Epoch 18/30\n",
      "1679/1679 - 12s - loss: 0.4381 - accuracy: 0.8027 - auc: 0.8460\n",
      "Epoch 19/30\n",
      "1679/1679 - 12s - loss: 0.4380 - accuracy: 0.8027 - auc: 0.8458\n",
      "Epoch 20/30\n",
      "1679/1679 - 12s - loss: 0.4375 - accuracy: 0.8028 - auc: 0.8463\n",
      "Epoch 21/30\n",
      "1679/1679 - 12s - loss: 0.4379 - accuracy: 0.8028 - auc: 0.8459\n",
      "Epoch 22/30\n",
      "1679/1679 - 11s - loss: 0.4378 - accuracy: 0.8034 - auc: 0.8460\n",
      "Epoch 23/30\n",
      "1679/1679 - 12s - loss: 0.4377 - accuracy: 0.8023 - auc: 0.8460\n",
      "Epoch 24/30\n",
      "1679/1679 - 12s - loss: 0.4376 - accuracy: 0.8034 - auc: 0.8462\n",
      "Epoch 25/30\n",
      "1679/1679 - 12s - loss: 0.4365 - accuracy: 0.8044 - auc: 0.8472\n",
      "Epoch 26/30\n",
      "1679/1679 - 11s - loss: 0.4371 - accuracy: 0.8035 - auc: 0.8468\n",
      "Epoch 27/30\n",
      "1679/1679 - 12s - loss: 0.4373 - accuracy: 0.8033 - auc: 0.8464\n",
      "Epoch 28/30\n",
      "1679/1679 - 11s - loss: 0.4370 - accuracy: 0.8039 - auc: 0.8467\n",
      "Epoch 29/30\n",
      "1679/1679 - 11s - loss: 0.4363 - accuracy: 0.8046 - auc: 0.8473\n",
      "Epoch 30/30\n",
      "1679/1679 - 12s - loss: 0.4364 - accuracy: 0.8047 - auc: 0.8471\n",
      "Epoch 1/30\n",
      "1679/1679 - 11s - loss: 0.6672 - accuracy: 0.7497 - auc: 0.7755\n",
      "Epoch 2/30\n",
      "1679/1679 - 12s - loss: 0.4647 - accuracy: 0.7843 - auc: 0.8268\n",
      "Epoch 3/30\n",
      "1679/1679 - 11s - loss: 0.4579 - accuracy: 0.7871 - auc: 0.8308\n",
      "Epoch 4/30\n",
      "1679/1679 - 11s - loss: 0.4517 - accuracy: 0.7910 - auc: 0.8350\n",
      "Epoch 5/30\n",
      "1679/1679 - 11s - loss: 0.4480 - accuracy: 0.7935 - auc: 0.8377\n",
      "Epoch 6/30\n",
      "1679/1679 - 11s - loss: 0.4480 - accuracy: 0.7929 - auc: 0.8378\n",
      "Epoch 7/30\n",
      "1679/1679 - 11s - loss: 0.4453 - accuracy: 0.7958 - auc: 0.8398\n",
      "Epoch 8/30\n",
      "1679/1679 - 11s - loss: 0.4429 - accuracy: 0.7975 - auc: 0.8415\n",
      "Epoch 9/30\n",
      "1679/1679 - 11s - loss: 0.4421 - accuracy: 0.7985 - auc: 0.8417\n",
      "Epoch 10/30\n",
      "1679/1679 - 11s - loss: 0.4411 - accuracy: 0.8002 - auc: 0.8429\n",
      "Epoch 11/30\n",
      "1679/1679 - 12s - loss: 0.4394 - accuracy: 0.8003 - auc: 0.8440\n",
      "Epoch 12/30\n",
      "1679/1679 - 12s - loss: 0.4400 - accuracy: 0.8000 - auc: 0.8437\n",
      "Epoch 13/30\n",
      "1679/1679 - 12s - loss: 0.4385 - accuracy: 0.8026 - auc: 0.8447\n",
      "Epoch 14/30\n",
      "1679/1679 - 11s - loss: 0.4389 - accuracy: 0.8009 - auc: 0.8444\n",
      "Epoch 15/30\n",
      "1679/1679 - 11s - loss: 0.4378 - accuracy: 0.8020 - auc: 0.8454\n",
      "Epoch 16/30\n",
      "1679/1679 - 11s - loss: 0.4376 - accuracy: 0.8027 - auc: 0.8455\n",
      "Epoch 17/30\n",
      "1679/1679 - 11s - loss: 0.4378 - accuracy: 0.8009 - auc: 0.8453\n",
      "Epoch 18/30\n",
      "1679/1679 - 11s - loss: 0.4373 - accuracy: 0.8027 - auc: 0.8460\n",
      "Epoch 19/30\n",
      "1679/1679 - 11s - loss: 0.4379 - accuracy: 0.8012 - auc: 0.8453\n",
      "Epoch 20/30\n",
      "1679/1679 - 12s - loss: 0.4371 - accuracy: 0.8022 - auc: 0.8462\n",
      "Epoch 21/30\n",
      "1679/1679 - 11s - loss: 0.4368 - accuracy: 0.8024 - auc: 0.8462\n",
      "Epoch 22/30\n",
      "1679/1679 - 11s - loss: 0.4371 - accuracy: 0.8028 - auc: 0.8460\n",
      "Epoch 23/30\n",
      "1679/1679 - 11s - loss: 0.4370 - accuracy: 0.8030 - auc: 0.8463\n",
      "Epoch 24/30\n",
      "1679/1679 - 11s - loss: 0.4364 - accuracy: 0.8032 - auc: 0.8466\n",
      "Epoch 25/30\n",
      "1679/1679 - 11s - loss: 0.4365 - accuracy: 0.8037 - auc: 0.8465\n",
      "Epoch 26/30\n",
      "1679/1679 - 11s - loss: 0.4363 - accuracy: 0.8037 - auc: 0.8466\n",
      "Epoch 27/30\n",
      "1679/1679 - 11s - loss: 0.4367 - accuracy: 0.8033 - auc: 0.8461\n",
      "Epoch 28/30\n",
      "1679/1679 - 11s - loss: 0.4364 - accuracy: 0.8043 - auc: 0.8465\n",
      "Epoch 29/30\n",
      "1679/1679 - 11s - loss: 0.4358 - accuracy: 0.8046 - auc: 0.8473\n",
      "Epoch 30/30\n",
      "1679/1679 - 11s - loss: 0.4356 - accuracy: 0.8046 - auc: 0.8472\n",
      "Epoch 1/30\n",
      "1679/1679 - 11s - loss: 0.5888 - accuracy: 0.7527 - auc: 0.7811\n",
      "Epoch 2/30\n",
      "1679/1679 - 11s - loss: 0.4661 - accuracy: 0.7840 - auc: 0.8273\n",
      "Epoch 3/30\n",
      "1679/1679 - 12s - loss: 0.4570 - accuracy: 0.7882 - auc: 0.8325\n",
      "Epoch 4/30\n",
      "1679/1679 - 11s - loss: 0.4516 - accuracy: 0.7916 - auc: 0.8355\n",
      "Epoch 5/30\n",
      "1679/1679 - 12s - loss: 0.4487 - accuracy: 0.7932 - auc: 0.8380\n",
      "Epoch 6/30\n",
      "1679/1679 - 12s - loss: 0.4474 - accuracy: 0.7952 - auc: 0.8390\n",
      "Epoch 7/30\n",
      "1679/1679 - 12s - loss: 0.4443 - accuracy: 0.7967 - auc: 0.8410\n",
      "Epoch 8/30\n",
      "1679/1679 - 11s - loss: 0.4434 - accuracy: 0.7976 - auc: 0.8417\n",
      "Epoch 9/30\n",
      "1679/1679 - 11s - loss: 0.4426 - accuracy: 0.7991 - auc: 0.8427\n",
      "Epoch 10/30\n",
      "1679/1679 - 12s - loss: 0.4418 - accuracy: 0.7985 - auc: 0.8430\n",
      "Epoch 11/30\n",
      "1679/1679 - 11s - loss: 0.4410 - accuracy: 0.7999 - auc: 0.8437\n",
      "Epoch 12/30\n",
      "1679/1679 - 12s - loss: 0.4403 - accuracy: 0.8009 - auc: 0.8442\n",
      "Epoch 13/30\n",
      "1679/1679 - 12s - loss: 0.4397 - accuracy: 0.8012 - auc: 0.8450\n",
      "Epoch 14/30\n",
      "1679/1679 - 12s - loss: 0.4394 - accuracy: 0.8020 - auc: 0.8451\n",
      "Epoch 15/30\n",
      "1679/1679 - 12s - loss: 0.4383 - accuracy: 0.8028 - auc: 0.8459\n",
      "Epoch 16/30\n",
      "1679/1679 - 12s - loss: 0.4386 - accuracy: 0.8027 - auc: 0.8457\n",
      "Epoch 17/30\n",
      "1679/1679 - 12s - loss: 0.4387 - accuracy: 0.8011 - auc: 0.8457\n",
      "Epoch 18/30\n",
      "1679/1679 - 12s - loss: 0.4382 - accuracy: 0.8030 - auc: 0.8458\n",
      "Epoch 19/30\n",
      "1679/1679 - 12s - loss: 0.4380 - accuracy: 0.8022 - auc: 0.8462\n",
      "Epoch 20/30\n",
      "1679/1679 - 12s - loss: 0.4377 - accuracy: 0.8026 - auc: 0.8465\n",
      "Epoch 21/30\n",
      "1679/1679 - 12s - loss: 0.4380 - accuracy: 0.8028 - auc: 0.8465\n",
      "Epoch 22/30\n",
      "1679/1679 - 12s - loss: 0.4375 - accuracy: 0.8038 - auc: 0.8463\n",
      "Epoch 23/30\n",
      "1679/1679 - 12s - loss: 0.4371 - accuracy: 0.8038 - auc: 0.8468\n",
      "Epoch 24/30\n",
      "1679/1679 - 12s - loss: 0.4377 - accuracy: 0.8025 - auc: 0.8459\n",
      "Epoch 25/30\n",
      "1679/1679 - 12s - loss: 0.4374 - accuracy: 0.8028 - auc: 0.8468\n",
      "Epoch 26/30\n",
      "1679/1679 - 12s - loss: 0.4367 - accuracy: 0.8045 - auc: 0.8471\n",
      "Epoch 27/30\n",
      "1679/1679 - 12s - loss: 0.4369 - accuracy: 0.8045 - auc: 0.8469\n",
      "Epoch 28/30\n",
      "1679/1679 - 12s - loss: 0.4370 - accuracy: 0.8037 - auc: 0.8470\n",
      "Epoch 29/30\n",
      "1679/1679 - 12s - loss: 0.4371 - accuracy: 0.8036 - auc: 0.8470\n",
      "Epoch 30/30\n",
      "1679/1679 - 12s - loss: 0.4367 - accuracy: 0.8036 - auc: 0.8470\n",
      "Epoch 1/30\n",
      "1679/1679 - 12s - loss: 0.6988 - accuracy: 0.7470 - auc: 0.7720\n",
      "Epoch 2/30\n",
      "1679/1679 - 12s - loss: 0.4692 - accuracy: 0.7801 - auc: 0.8242\n",
      "Epoch 3/30\n",
      "1679/1679 - 12s - loss: 0.4599 - accuracy: 0.7858 - auc: 0.8302\n",
      "Epoch 4/30\n",
      "1679/1679 - 12s - loss: 0.4507 - accuracy: 0.7909 - auc: 0.8364\n",
      "Epoch 5/30\n",
      "1679/1679 - 12s - loss: 0.4500 - accuracy: 0.7902 - auc: 0.8367\n",
      "Epoch 6/30\n",
      "1679/1679 - 12s - loss: 0.4455 - accuracy: 0.7954 - auc: 0.8398\n",
      "Epoch 7/30\n",
      "1679/1679 - 12s - loss: 0.4456 - accuracy: 0.7963 - auc: 0.8400\n",
      "Epoch 8/30\n",
      "1679/1679 - 12s - loss: 0.4429 - accuracy: 0.7972 - auc: 0.8420\n",
      "Epoch 9/30\n",
      "1679/1679 - 12s - loss: 0.4428 - accuracy: 0.7967 - auc: 0.8416\n",
      "Epoch 10/30\n",
      "1679/1679 - 12s - loss: 0.4394 - accuracy: 0.7997 - auc: 0.8446\n",
      "Epoch 11/30\n",
      "1679/1679 - 12s - loss: 0.4409 - accuracy: 0.7997 - auc: 0.8429\n",
      "Epoch 12/30\n",
      "1679/1679 - 14s - loss: 0.4389 - accuracy: 0.8003 - auc: 0.8447\n",
      "Epoch 13/30\n",
      "1679/1679 - 14s - loss: 0.4388 - accuracy: 0.8010 - auc: 0.8448\n",
      "Epoch 14/30\n",
      "1679/1679 - 14s - loss: 0.4379 - accuracy: 0.8012 - auc: 0.8458\n",
      "Epoch 15/30\n",
      "1679/1679 - 14s - loss: 0.4383 - accuracy: 0.8008 - auc: 0.8449\n",
      "Epoch 16/30\n",
      "1679/1679 - 14s - loss: 0.4366 - accuracy: 0.8036 - auc: 0.8467\n",
      "Epoch 17/30\n",
      "1679/1679 - 14s - loss: 0.4365 - accuracy: 0.8025 - auc: 0.8467\n",
      "Epoch 18/30\n",
      "1679/1679 - 14s - loss: 0.4369 - accuracy: 0.8029 - auc: 0.8460\n",
      "Epoch 19/30\n",
      "1679/1679 - 14s - loss: 0.4364 - accuracy: 0.8028 - auc: 0.8466\n",
      "Epoch 20/30\n",
      "1679/1679 - 14s - loss: 0.4362 - accuracy: 0.8030 - auc: 0.8472\n",
      "Epoch 21/30\n",
      "1679/1679 - 14s - loss: 0.4359 - accuracy: 0.8039 - auc: 0.8474\n",
      "Epoch 22/30\n",
      "1679/1679 - 14s - loss: 0.4368 - accuracy: 0.8027 - auc: 0.8465\n",
      "Epoch 23/30\n",
      "1679/1679 - 14s - loss: 0.4362 - accuracy: 0.8039 - auc: 0.8470\n",
      "Epoch 24/30\n",
      "1679/1679 - 14s - loss: 0.4362 - accuracy: 0.8043 - auc: 0.8467\n",
      "Epoch 25/30\n",
      "1679/1679 - 14s - loss: 0.4356 - accuracy: 0.8036 - auc: 0.8476\n",
      "Epoch 26/30\n",
      "1679/1679 - 14s - loss: 0.4359 - accuracy: 0.8032 - auc: 0.8469\n",
      "Epoch 27/30\n",
      "1679/1679 - 14s - loss: 0.4355 - accuracy: 0.8039 - auc: 0.8475\n",
      "Epoch 28/30\n",
      "1679/1679 - 14s - loss: 0.4355 - accuracy: 0.8046 - auc: 0.8473\n",
      "Epoch 29/30\n",
      "1679/1679 - 14s - loss: 0.4350 - accuracy: 0.8037 - auc: 0.8478\n",
      "Epoch 30/30\n",
      "1679/1679 - 14s - loss: 0.4355 - accuracy: 0.8038 - auc: 0.8473\n",
      "Epoch 1/30\n",
      "1679/1679 - 14s - loss: 0.6735 - accuracy: 0.7452 - auc: 0.7717\n",
      "Epoch 2/30\n",
      "1679/1679 - 14s - loss: 0.4681 - accuracy: 0.7820 - auc: 0.8252\n",
      "Epoch 3/30\n",
      "1679/1679 - 14s - loss: 0.4578 - accuracy: 0.7864 - auc: 0.8323\n",
      "Epoch 4/30\n",
      "1679/1679 - 14s - loss: 0.4545 - accuracy: 0.7886 - auc: 0.8338\n",
      "Epoch 5/30\n",
      "1679/1679 - 14s - loss: 0.4481 - accuracy: 0.7939 - auc: 0.8386\n",
      "Epoch 6/30\n",
      "1679/1679 - 14s - loss: 0.4474 - accuracy: 0.7942 - auc: 0.8393\n",
      "Epoch 7/30\n",
      "1679/1679 - 14s - loss: 0.4463 - accuracy: 0.7957 - auc: 0.8399\n",
      "Epoch 8/30\n",
      "1679/1679 - 14s - loss: 0.4437 - accuracy: 0.7977 - auc: 0.8416\n",
      "Epoch 9/30\n",
      "1679/1679 - 14s - loss: 0.4423 - accuracy: 0.7991 - auc: 0.8430\n",
      "Epoch 10/30\n",
      "1679/1679 - 14s - loss: 0.4416 - accuracy: 0.7987 - auc: 0.8432\n",
      "Epoch 11/30\n",
      "1679/1679 - 14s - loss: 0.4410 - accuracy: 0.7989 - auc: 0.8439\n",
      "Epoch 12/30\n",
      "1679/1679 - 14s - loss: 0.4402 - accuracy: 0.7998 - auc: 0.8442\n",
      "Epoch 13/30\n",
      "1679/1679 - 14s - loss: 0.4397 - accuracy: 0.8000 - auc: 0.8446\n",
      "Epoch 14/30\n",
      "1679/1679 - 14s - loss: 0.4398 - accuracy: 0.8003 - auc: 0.8451\n",
      "Epoch 15/30\n",
      "1679/1679 - 14s - loss: 0.4392 - accuracy: 0.8008 - auc: 0.8449\n",
      "Epoch 16/30\n",
      "1679/1679 - 14s - loss: 0.4385 - accuracy: 0.8020 - auc: 0.8455\n",
      "Epoch 17/30\n",
      "1679/1679 - 14s - loss: 0.4385 - accuracy: 0.8023 - auc: 0.8456\n",
      "Epoch 18/30\n",
      "1679/1679 - 14s - loss: 0.4390 - accuracy: 0.8012 - auc: 0.8456\n",
      "Epoch 19/30\n",
      "1679/1679 - 14s - loss: 0.4378 - accuracy: 0.8017 - auc: 0.8463\n",
      "Epoch 20/30\n",
      "1679/1679 - 14s - loss: 0.4375 - accuracy: 0.8020 - auc: 0.8464\n",
      "Epoch 21/30\n",
      "1679/1679 - 14s - loss: 0.4373 - accuracy: 0.8028 - auc: 0.8466\n",
      "Epoch 22/30\n",
      "1679/1679 - 14s - loss: 0.4377 - accuracy: 0.8026 - auc: 0.8465\n",
      "Epoch 23/30\n",
      "1679/1679 - 14s - loss: 0.4369 - accuracy: 0.8027 - auc: 0.8471\n",
      "Epoch 24/30\n",
      "1679/1679 - 14s - loss: 0.4372 - accuracy: 0.8035 - auc: 0.8467\n",
      "Epoch 25/30\n",
      "1679/1679 - 14s - loss: 0.4370 - accuracy: 0.8042 - auc: 0.8472\n",
      "Epoch 26/30\n",
      "1679/1679 - 13s - loss: 0.4371 - accuracy: 0.8037 - auc: 0.8470\n",
      "Epoch 27/30\n",
      "1679/1679 - 14s - loss: 0.4366 - accuracy: 0.8035 - auc: 0.8472\n",
      "Epoch 28/30\n",
      "1679/1679 - 14s - loss: 0.4367 - accuracy: 0.8036 - auc: 0.8473\n",
      "Epoch 29/30\n",
      "1679/1679 - 14s - loss: 0.4367 - accuracy: 0.8036 - auc: 0.8470\n",
      "Epoch 30/30\n",
      "1679/1679 - 14s - loss: 0.4368 - accuracy: 0.8032 - auc: 0.8470\n"
     ]
    }
   ],
   "source": [
    "# 10 fold\n",
    "kfolds = 10 # 4 = 75% train, 25% validation\n",
    "split = KFold(n_splits=kfolds, shuffle=True, random_state=42)\n",
    "\n",
    "X = data_cln.drop([\"is_canceled\"], axis=1)[features]\n",
    "y = data_cln[\"is_canceled\"].to_numpy()\n",
    "\n",
    "X = preprocessor.fit_transform(X)\n",
    "\n",
    "result = []\n",
    "\n",
    "for train_index, test_index in split.split(y):\n",
    "    train_x = X[train_index]\n",
    "    train_y = y[train_index]\n",
    "    \n",
    "    test_x = X[test_index]\n",
    "    test_y = y[test_index]\n",
    "    \n",
    "    model = test_model_1()\n",
    "    \n",
    "    history = model.fit(train_x, train_y, batch_size=64, epochs=30, verbose = 2)\n",
    "    pred_y = model.predict(test_x)\n",
    "    result.append({'pred': pred_y, 'test': test_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_accuracy = []\n",
    "total_f1 = []\n",
    "total_pre = []\n",
    "total_recall = []\n",
    "total_auc = []\n",
    "for i in range(10):\n",
    "    pred = result[i]['pred']\n",
    "    test = result[i]['test']\n",
    "    fpr, tpr, _ = roc_curve(test, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    total_auc.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=0.8)\n",
    "    t_acc = []\n",
    "    t_f1 = []\n",
    "    t_pre = []\n",
    "    t_rec = []\n",
    "    for t in np.arange(0,1,0.05):\n",
    "        p_val = np.zeros(pred.shape)\n",
    "        p_val[pred > t] = 1\n",
    "        t_acc.append(accuracy_score(test, p_val))\n",
    "        t_f1.append(f1_score(test, p_val))\n",
    "        t_pre.append(precision_score(test, p_val))\n",
    "        t_rec.append(recall_score(test, p_val)) \n",
    "    total_accuracy.append(np.max(t_acc))\n",
    "    total_f1.append(np.max(t_f1))\n",
    "    total_pre.append(np.max(t_pre))\n",
    "    total_recall.append(np.max(t_rec)) \n",
    "    \n",
    "plt.savefig('totalDNN.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_res = {'auc':total_auc, 'acc': total_accuracy, 'f1': total_f1,\n",
    "            'pre': total_pre, 'recall': total_recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc \t 0.8448246871227247 0.8564099937841168 0.8490064990255212\n",
      "acc \t 0.7980567886757685 0.8106206549962308 0.8065248345757601\n",
      "f1 \t 0.7016567904220583 0.7253886010362695 0.7140002761335114\n",
      "pre \t 0.9887719298245614 0.9976744186046511 0.9929553840110511\n",
      "recall \t 1.0 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# total\n",
    "for k, v in total_res.items():\n",
    "    print(k, '\\t', min(v), max(v), np.average(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': [0.8564099937841168,\n",
       "  0.8485514897617665,\n",
       "  0.8457914647321594,\n",
       "  0.8462034514389434,\n",
       "  0.8455577817577679,\n",
       "  0.8512080798610512,\n",
       "  0.8526034164532483,\n",
       "  0.8488320188023902,\n",
       "  0.8448246871227247,\n",
       "  0.8500826065410425],\n",
       " 'acc': [0.8106206549962308,\n",
       "  0.8029148169863473,\n",
       "  0.8089454728201692,\n",
       "  0.7980567886757685,\n",
       "  0.8060976631208644,\n",
       "  0.807689086188123,\n",
       "  0.8105368958874277,\n",
       "  0.8096993047993969,\n",
       "  0.8013233939190887,\n",
       "  0.8093642683641846],\n",
       " 'f1': [0.7253886010362695,\n",
       "  0.7119322193457284,\n",
       "  0.7114249334413705,\n",
       "  0.7058565955117679,\n",
       "  0.7016567904220583,\n",
       "  0.7206420394193319,\n",
       "  0.7234042553191489,\n",
       "  0.7137462235649547,\n",
       "  0.711699779249448,\n",
       "  0.714251324025036],\n",
       " 'pre': [0.9947780678851175,\n",
       "  0.9919946631087392,\n",
       "  0.9928571428571429,\n",
       "  0.9925775978407557,\n",
       "  0.9898580121703854,\n",
       "  0.9941060903732809,\n",
       "  0.9976744186046511,\n",
       "  0.9938900203665988,\n",
       "  0.9887719298245614,\n",
       "  0.9930458970792768],\n",
       " 'recall': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8490064990255212"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(total_res['auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8065248345757601"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(total_res['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
