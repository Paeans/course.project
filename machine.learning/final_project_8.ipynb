{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_validate, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('hotel_bookings.csv')\n",
    "data_cln = data.fillna({'children': 0.0, 'country': 'Unknown', 'agent':0, 'company': 0})\n",
    "data_cln['meal'].replace('Undefined', 'SC', inplace = True)\n",
    "\n",
    "num_features = [\"lead_time\",\"arrival_date_week_number\",\"arrival_date_day_of_month\",\n",
    "                \"stays_in_weekend_nights\",\"stays_in_week_nights\",\"adults\",\"children\",\n",
    "                \"babies\",\"is_repeated_guest\", \"previous_cancellations\",\n",
    "                \"previous_bookings_not_canceled\",\"agent\",\"company\",\n",
    "                \"required_car_parking_spaces\", \"total_of_special_requests\", \"adr\"]\n",
    "\n",
    "cat_features = [\"arrival_date_month\",\"meal\",\"market_segment\",\n",
    "                \"distribution_channel\",\"reserved_room_type\",\"deposit_type\",\"customer_type\"]\n",
    "\n",
    "# Separate features and predicted value\n",
    "features = num_features + cat_features\n",
    "\n",
    "# preprocess numerical feats:\n",
    "# for most num cols, except the dates, 0 is the most logical choice as fill value\n",
    "# and here no dates are missing.\n",
    "num_transformer = SimpleImputer(strategy=\"constant\")\n",
    "\n",
    "# Preprocessing for categorical features:\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical features:\n",
    "preprocessor = ColumnTransformer(transformers=[(\"num\", num_transformer, num_features),\n",
    "                                               (\"cat\", cat_transformer, cat_features)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resort_data = data_cln[data_cln.hotel == 'Resort Hotel']\n",
    "city_data = data_cln[data_cln.hotel == 'City Hotel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_1():\n",
    "    inputs = keras.Input(shape=(60,), dtype = \"float32\")\n",
    "    \n",
    "    x = layers.Dense(256)(inputs)\n",
    "#     x = layers.Dense(256)(x)\n",
    "#     x = layers.Dense(256)(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = layers.Dense(64)(x)\n",
    "    x = layers.Dense(32)(x)\n",
    "    x = layers.Dense(16)(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid',\n",
    "                    kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4))(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    # model.summary()\n",
    "\n",
    "    model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\", \"AUC\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kfolds = 10 \n",
    "# kf = KFold(n_splits=kfolds, shuffle=True, random_state=42)\n",
    "# accuracy_res = []\n",
    "# pred_res = []\n",
    "# for train_index, test_index in kf.split(y):\n",
    "#     train_x = X[train_index]\n",
    "#     train_y = y[train_index]\n",
    "    \n",
    "#     test_x = X[test_index]\n",
    "#     test_y = y[test_index]\n",
    "    \n",
    "#     model = test_model_1()\n",
    "    \n",
    "#     history = model.fit(train_x, train_y, batch_size=64, epochs=30, )\n",
    "#     pred_y = model.predict(test_x)\n",
    "#     pred_res.append({'pred': pred_y, 'real': test_y})\n",
    "#     tmp = []\n",
    "#     for i in np.arange(0, 1, 0.01):\n",
    "#         tmp_y = np.zeros(pred_y.shape)\n",
    "#         tmp_y[pred_y > i] = 1\n",
    "#         tmp.append(accuracy_score(test_y, tmp_y))\n",
    "#     print(max(tmp))\n",
    "#     accuracy_res.append(max(tmp))\n",
    "        \n",
    "# accuracy_val = np.array(accuracy_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1116/1116 - 7s - loss: 0.7596 - accuracy: 0.7287 - auc: 0.7658\n",
      "Epoch 2/30\n",
      "1116/1116 - 7s - loss: 0.4775 - accuracy: 0.7756 - auc: 0.8273\n",
      "Epoch 3/30\n",
      "1116/1116 - 7s - loss: 0.4660 - accuracy: 0.7825 - auc: 0.8339\n",
      "Epoch 4/30\n",
      "1116/1116 - 6s - loss: 0.4611 - accuracy: 0.7861 - auc: 0.8370\n",
      "Epoch 5/30\n",
      "1116/1116 - 7s - loss: 0.4564 - accuracy: 0.7888 - auc: 0.8399\n",
      "Epoch 6/30\n",
      "1116/1116 - 7s - loss: 0.4556 - accuracy: 0.7892 - auc: 0.8401\n",
      "Epoch 7/30\n",
      "1116/1116 - 7s - loss: 0.4532 - accuracy: 0.7911 - auc: 0.8419\n",
      "Epoch 8/30\n",
      "1116/1116 - 7s - loss: 0.4519 - accuracy: 0.7932 - auc: 0.8422\n",
      "Epoch 9/30\n",
      "1116/1116 - 7s - loss: 0.4510 - accuracy: 0.7923 - auc: 0.8434\n",
      "Epoch 10/30\n",
      "1116/1116 - 7s - loss: 0.4493 - accuracy: 0.7961 - auc: 0.8448\n",
      "Epoch 11/30\n",
      "1116/1116 - 7s - loss: 0.4479 - accuracy: 0.7961 - auc: 0.8452\n",
      "Epoch 12/30\n",
      "1116/1116 - 8s - loss: 0.4475 - accuracy: 0.7947 - auc: 0.8453\n",
      "Epoch 13/30\n",
      "1116/1116 - 8s - loss: 0.4471 - accuracy: 0.7977 - auc: 0.8458\n",
      "Epoch 14/30\n",
      "1116/1116 - 8s - loss: 0.4450 - accuracy: 0.7973 - auc: 0.8471\n",
      "Epoch 15/30\n",
      "1116/1116 - 8s - loss: 0.4447 - accuracy: 0.7968 - auc: 0.8475\n",
      "Epoch 16/30\n",
      "1116/1116 - 8s - loss: 0.4452 - accuracy: 0.7985 - auc: 0.8471\n",
      "Epoch 17/30\n",
      "1116/1116 - 8s - loss: 0.4443 - accuracy: 0.7977 - auc: 0.8476\n",
      "Epoch 18/30\n",
      "1116/1116 - 8s - loss: 0.4439 - accuracy: 0.7991 - auc: 0.8481\n",
      "Epoch 19/30\n",
      "1116/1116 - 8s - loss: 0.4434 - accuracy: 0.7998 - auc: 0.8486\n",
      "Epoch 20/30\n",
      "1116/1116 - 8s - loss: 0.4434 - accuracy: 0.7990 - auc: 0.8485\n",
      "Epoch 21/30\n",
      "1116/1116 - 8s - loss: 0.4431 - accuracy: 0.7992 - auc: 0.8484\n",
      "Epoch 22/30\n",
      "1116/1116 - 8s - loss: 0.4432 - accuracy: 0.8004 - auc: 0.8487\n",
      "Epoch 23/30\n",
      "1116/1116 - 8s - loss: 0.4420 - accuracy: 0.8016 - auc: 0.8496\n",
      "Epoch 24/30\n",
      "1116/1116 - 8s - loss: 0.4427 - accuracy: 0.8008 - auc: 0.8488\n",
      "Epoch 25/30\n",
      "1116/1116 - 8s - loss: 0.4422 - accuracy: 0.8007 - auc: 0.8494\n",
      "Epoch 26/30\n",
      "1116/1116 - 8s - loss: 0.4421 - accuracy: 0.7996 - auc: 0.8498\n",
      "Epoch 27/30\n",
      "1116/1116 - 8s - loss: 0.4416 - accuracy: 0.8008 - auc: 0.8497\n",
      "Epoch 28/30\n",
      "1116/1116 - 8s - loss: 0.4420 - accuracy: 0.8017 - auc: 0.8492\n",
      "Epoch 29/30\n",
      "1116/1116 - 8s - loss: 0.4421 - accuracy: 0.8017 - auc: 0.8495\n",
      "Epoch 30/30\n",
      "1116/1116 - 8s - loss: 0.4418 - accuracy: 0.8019 - auc: 0.8496\n",
      "Epoch 1/30\n",
      "1116/1116 - 8s - loss: 0.6872 - accuracy: 0.7395 - auc: 0.7788\n",
      "Epoch 2/30\n",
      "1116/1116 - 8s - loss: 0.4732 - accuracy: 0.7796 - auc: 0.8295\n",
      "Epoch 3/30\n",
      "1116/1116 - 8s - loss: 0.4663 - accuracy: 0.7842 - auc: 0.8338\n",
      "Epoch 4/30\n",
      "1116/1116 - 8s - loss: 0.4609 - accuracy: 0.7874 - auc: 0.8379\n",
      "Epoch 5/30\n",
      "1116/1116 - 8s - loss: 0.4576 - accuracy: 0.7890 - auc: 0.8386\n",
      "Epoch 6/30\n",
      "1116/1116 - 8s - loss: 0.4524 - accuracy: 0.7928 - auc: 0.8421\n",
      "Epoch 7/30\n",
      "1116/1116 - 8s - loss: 0.4518 - accuracy: 0.7928 - auc: 0.8429\n",
      "Epoch 8/30\n",
      "1116/1116 - 8s - loss: 0.4508 - accuracy: 0.7933 - auc: 0.8432\n",
      "Epoch 9/30\n",
      "1116/1116 - 8s - loss: 0.4488 - accuracy: 0.7952 - auc: 0.8448\n",
      "Epoch 10/30\n",
      "1116/1116 - 8s - loss: 0.4464 - accuracy: 0.7965 - auc: 0.8468\n",
      "Epoch 11/30\n",
      "1116/1116 - 8s - loss: 0.4466 - accuracy: 0.7974 - auc: 0.8461\n",
      "Epoch 12/30\n",
      "1116/1116 - 8s - loss: 0.4462 - accuracy: 0.7978 - auc: 0.8468\n",
      "Epoch 13/30\n",
      "1116/1116 - 8s - loss: 0.4459 - accuracy: 0.7974 - auc: 0.8464\n",
      "Epoch 14/30\n",
      "1116/1116 - 8s - loss: 0.4439 - accuracy: 0.7995 - auc: 0.8482\n",
      "Epoch 15/30\n",
      "1116/1116 - 8s - loss: 0.4438 - accuracy: 0.7990 - auc: 0.8484\n",
      "Epoch 16/30\n",
      "1116/1116 - 8s - loss: 0.4441 - accuracy: 0.7993 - auc: 0.8479\n",
      "Epoch 17/30\n",
      "1116/1116 - 8s - loss: 0.4428 - accuracy: 0.8007 - auc: 0.8490\n",
      "Epoch 18/30\n",
      "1116/1116 - 8s - loss: 0.4426 - accuracy: 0.8000 - auc: 0.8490\n",
      "Epoch 19/30\n",
      "1116/1116 - 8s - loss: 0.4426 - accuracy: 0.8003 - auc: 0.8492\n",
      "Epoch 20/30\n",
      "1116/1116 - 8s - loss: 0.4419 - accuracy: 0.8019 - auc: 0.8496\n",
      "Epoch 21/30\n",
      "1116/1116 - 8s - loss: 0.4424 - accuracy: 0.8008 - auc: 0.8495\n",
      "Epoch 22/30\n",
      "1116/1116 - 8s - loss: 0.4420 - accuracy: 0.8010 - auc: 0.8495\n",
      "Epoch 23/30\n",
      "1116/1116 - 8s - loss: 0.4420 - accuracy: 0.8012 - auc: 0.8495\n",
      "Epoch 24/30\n",
      "1116/1116 - 8s - loss: 0.4416 - accuracy: 0.8011 - auc: 0.8498\n",
      "Epoch 25/30\n",
      "1116/1116 - 8s - loss: 0.4415 - accuracy: 0.8017 - auc: 0.8500\n",
      "Epoch 26/30\n",
      "1116/1116 - 8s - loss: 0.4411 - accuracy: 0.8014 - auc: 0.8500\n",
      "Epoch 27/30\n",
      "1116/1116 - 8s - loss: 0.4420 - accuracy: 0.8017 - auc: 0.8490\n",
      "Epoch 28/30\n",
      "1116/1116 - 8s - loss: 0.4410 - accuracy: 0.8014 - auc: 0.8506\n",
      "Epoch 29/30\n",
      "1116/1116 - 8s - loss: 0.4413 - accuracy: 0.8019 - auc: 0.8502\n",
      "Epoch 30/30\n",
      "1116/1116 - 8s - loss: 0.4410 - accuracy: 0.8020 - auc: 0.8503\n",
      "Epoch 1/30\n",
      "1116/1116 - 8s - loss: 0.7633 - accuracy: 0.7328 - auc: 0.7692\n",
      "Epoch 2/30\n",
      "1116/1116 - 8s - loss: 0.4742 - accuracy: 0.7797 - auc: 0.8297\n",
      "Epoch 3/30\n",
      "1116/1116 - 8s - loss: 0.4665 - accuracy: 0.7824 - auc: 0.8345\n",
      "Epoch 4/30\n",
      "1116/1116 - 8s - loss: 0.4614 - accuracy: 0.7847 - auc: 0.8368\n",
      "Epoch 5/30\n",
      "1116/1116 - 8s - loss: 0.4567 - accuracy: 0.7886 - auc: 0.8392\n",
      "Epoch 6/30\n",
      "1116/1116 - 8s - loss: 0.4522 - accuracy: 0.7916 - auc: 0.8418\n",
      "Epoch 7/30\n",
      "1116/1116 - 8s - loss: 0.4518 - accuracy: 0.7927 - auc: 0.8430\n",
      "Epoch 8/30\n",
      "1116/1116 - 8s - loss: 0.4492 - accuracy: 0.7941 - auc: 0.8443\n",
      "Epoch 9/30\n",
      "1116/1116 - 8s - loss: 0.4487 - accuracy: 0.7938 - auc: 0.8446\n",
      "Epoch 10/30\n",
      "1116/1116 - 8s - loss: 0.4462 - accuracy: 0.7961 - auc: 0.8467\n",
      "Epoch 11/30\n",
      "1116/1116 - 8s - loss: 0.4460 - accuracy: 0.7961 - auc: 0.8466\n",
      "Epoch 12/30\n",
      "1116/1116 - 8s - loss: 0.4443 - accuracy: 0.7984 - auc: 0.8482\n",
      "Epoch 13/30\n",
      "1116/1116 - 8s - loss: 0.4461 - accuracy: 0.7966 - auc: 0.8461\n",
      "Epoch 14/30\n",
      "1116/1116 - 8s - loss: 0.4434 - accuracy: 0.7988 - auc: 0.8482\n",
      "Epoch 15/30\n",
      "1116/1116 - 8s - loss: 0.4435 - accuracy: 0.7972 - auc: 0.8485\n",
      "Epoch 16/30\n",
      "1116/1116 - 8s - loss: 0.4424 - accuracy: 0.7984 - auc: 0.8487\n",
      "Epoch 17/30\n",
      "1116/1116 - 8s - loss: 0.4423 - accuracy: 0.7996 - auc: 0.8491\n",
      "Epoch 18/30\n",
      "1116/1116 - 8s - loss: 0.4412 - accuracy: 0.7997 - auc: 0.8499\n",
      "Epoch 19/30\n",
      "1116/1116 - 8s - loss: 0.4420 - accuracy: 0.7989 - auc: 0.8488\n",
      "Epoch 20/30\n",
      "1116/1116 - 8s - loss: 0.4416 - accuracy: 0.8002 - auc: 0.8497\n",
      "Epoch 21/30\n",
      "1116/1116 - 8s - loss: 0.4407 - accuracy: 0.7994 - auc: 0.8504\n",
      "Epoch 22/30\n",
      "1116/1116 - 8s - loss: 0.4409 - accuracy: 0.8010 - auc: 0.8504\n",
      "Epoch 23/30\n",
      "1116/1116 - 8s - loss: 0.4409 - accuracy: 0.8014 - auc: 0.8495\n",
      "Epoch 24/30\n",
      "1116/1116 - 8s - loss: 0.4399 - accuracy: 0.8013 - auc: 0.8506\n",
      "Epoch 25/30\n",
      "1116/1116 - 8s - loss: 0.4401 - accuracy: 0.8015 - auc: 0.8505\n",
      "Epoch 26/30\n",
      "1116/1116 - 8s - loss: 0.4401 - accuracy: 0.8006 - auc: 0.8506\n",
      "Epoch 27/30\n",
      "1116/1116 - 8s - loss: 0.4402 - accuracy: 0.8013 - auc: 0.8505\n",
      "Epoch 28/30\n",
      "1116/1116 - 8s - loss: 0.4400 - accuracy: 0.8018 - auc: 0.8509\n",
      "Epoch 29/30\n",
      "1116/1116 - 8s - loss: 0.4399 - accuracy: 0.8014 - auc: 0.8510\n",
      "Epoch 30/30\n",
      "1116/1116 - 8s - loss: 0.4396 - accuracy: 0.8009 - auc: 0.8507\n",
      "Epoch 1/30\n",
      "1116/1116 - 8s - loss: 0.8237 - accuracy: 0.7311 - auc: 0.7663\n",
      "Epoch 2/30\n",
      "1116/1116 - 8s - loss: 0.4753 - accuracy: 0.7786 - auc: 0.8291\n",
      "Epoch 3/30\n",
      "1116/1116 - 8s - loss: 0.4650 - accuracy: 0.7835 - auc: 0.8350\n",
      "Epoch 4/30\n",
      "1116/1116 - 8s - loss: 0.4634 - accuracy: 0.7844 - auc: 0.8361\n",
      "Epoch 5/30\n",
      "1116/1116 - 8s - loss: 0.4579 - accuracy: 0.7892 - auc: 0.8393\n",
      "Epoch 6/30\n",
      "1116/1116 - 8s - loss: 0.4541 - accuracy: 0.7908 - auc: 0.8415\n",
      "Epoch 7/30\n",
      "1116/1116 - 8s - loss: 0.4531 - accuracy: 0.7920 - auc: 0.8418\n",
      "Epoch 8/30\n",
      "1116/1116 - 8s - loss: 0.4497 - accuracy: 0.7939 - auc: 0.8447\n",
      "Epoch 9/30\n",
      "1116/1116 - 8s - loss: 0.4498 - accuracy: 0.7951 - auc: 0.8447\n",
      "Epoch 10/30\n",
      "1116/1116 - 8s - loss: 0.4479 - accuracy: 0.7962 - auc: 0.8451\n",
      "Epoch 11/30\n",
      "1116/1116 - 8s - loss: 0.4467 - accuracy: 0.7972 - auc: 0.8460\n",
      "Epoch 12/30\n",
      "1116/1116 - 8s - loss: 0.4460 - accuracy: 0.7968 - auc: 0.8471\n",
      "Epoch 13/30\n",
      "1116/1116 - 8s - loss: 0.4452 - accuracy: 0.7980 - auc: 0.8477\n",
      "Epoch 14/30\n",
      "1116/1116 - 8s - loss: 0.4453 - accuracy: 0.7975 - auc: 0.8477\n",
      "Epoch 15/30\n",
      "1116/1116 - 8s - loss: 0.4442 - accuracy: 0.7975 - auc: 0.8480\n",
      "Epoch 16/30\n",
      "1116/1116 - 8s - loss: 0.4429 - accuracy: 0.7998 - auc: 0.8491\n",
      "Epoch 17/30\n",
      "1116/1116 - 8s - loss: 0.4426 - accuracy: 0.7993 - auc: 0.8495\n",
      "Epoch 18/30\n",
      "1116/1116 - 8s - loss: 0.4438 - accuracy: 0.7991 - auc: 0.8480\n",
      "Epoch 19/30\n",
      "1116/1116 - 8s - loss: 0.4428 - accuracy: 0.7995 - auc: 0.8489\n",
      "Epoch 20/30\n",
      "1116/1116 - 8s - loss: 0.4425 - accuracy: 0.7994 - auc: 0.8495\n",
      "Epoch 21/30\n",
      "1116/1116 - 8s - loss: 0.4422 - accuracy: 0.8018 - auc: 0.8495\n",
      "Epoch 22/30\n",
      "1116/1116 - 8s - loss: 0.4427 - accuracy: 0.8007 - auc: 0.8492\n",
      "Epoch 23/30\n",
      "1116/1116 - 8s - loss: 0.4414 - accuracy: 0.8012 - auc: 0.8500\n",
      "Epoch 24/30\n",
      "1116/1116 - 8s - loss: 0.4408 - accuracy: 0.8007 - auc: 0.8504\n",
      "Epoch 25/30\n",
      "1116/1116 - 8s - loss: 0.4417 - accuracy: 0.8026 - auc: 0.8500\n",
      "Epoch 26/30\n",
      "1116/1116 - 8s - loss: 0.4412 - accuracy: 0.8016 - auc: 0.8502\n",
      "Epoch 27/30\n",
      "1116/1116 - 8s - loss: 0.4411 - accuracy: 0.8017 - auc: 0.8502\n",
      "Epoch 28/30\n",
      "1116/1116 - 8s - loss: 0.4409 - accuracy: 0.8025 - auc: 0.8507\n",
      "Epoch 29/30\n",
      "1116/1116 - 8s - loss: 0.4409 - accuracy: 0.8022 - auc: 0.8507\n",
      "Epoch 30/30\n",
      "1116/1116 - 8s - loss: 0.4411 - accuracy: 0.8027 - auc: 0.8506\n",
      "Epoch 1/30\n",
      "1116/1116 - 8s - loss: 0.7687 - accuracy: 0.7315 - auc: 0.7688\n",
      "Epoch 2/30\n",
      "1116/1116 - 8s - loss: 0.4789 - accuracy: 0.7753 - auc: 0.8272\n",
      "Epoch 3/30\n",
      "1116/1116 - 8s - loss: 0.4656 - accuracy: 0.7831 - auc: 0.8349\n",
      "Epoch 4/30\n",
      "1116/1116 - 8s - loss: 0.4602 - accuracy: 0.7869 - auc: 0.8378\n",
      "Epoch 5/30\n",
      "1116/1116 - 8s - loss: 0.4608 - accuracy: 0.7864 - auc: 0.8375\n",
      "Epoch 6/30\n",
      "1116/1116 - 8s - loss: 0.4532 - accuracy: 0.7921 - auc: 0.8420\n",
      "Epoch 7/30\n",
      "1116/1116 - 8s - loss: 0.4527 - accuracy: 0.7916 - auc: 0.8420\n",
      "Epoch 8/30\n",
      "1116/1116 - 8s - loss: 0.4515 - accuracy: 0.7933 - auc: 0.8428\n",
      "Epoch 9/30\n",
      "1116/1116 - 8s - loss: 0.4497 - accuracy: 0.7950 - auc: 0.8449\n",
      "Epoch 10/30\n",
      "1116/1116 - 8s - loss: 0.4499 - accuracy: 0.7950 - auc: 0.8439\n",
      "Epoch 11/30\n",
      "1116/1116 - 8s - loss: 0.4491 - accuracy: 0.7936 - auc: 0.8447\n",
      "Epoch 12/30\n",
      "1116/1116 - 8s - loss: 0.4460 - accuracy: 0.7956 - auc: 0.8467\n",
      "Epoch 13/30\n",
      "1116/1116 - 8s - loss: 0.4467 - accuracy: 0.7975 - auc: 0.8462\n",
      "Epoch 14/30\n",
      "1116/1116 - 8s - loss: 0.4456 - accuracy: 0.7982 - auc: 0.8471\n",
      "Epoch 15/30\n",
      "1116/1116 - 8s - loss: 0.4442 - accuracy: 0.7995 - auc: 0.8480\n",
      "Epoch 16/30\n",
      "1116/1116 - 8s - loss: 0.4450 - accuracy: 0.7988 - auc: 0.8472\n",
      "Epoch 17/30\n",
      "1116/1116 - 8s - loss: 0.4445 - accuracy: 0.7985 - auc: 0.8479\n",
      "Epoch 18/30\n",
      "1116/1116 - 8s - loss: 0.4439 - accuracy: 0.7988 - auc: 0.8488\n",
      "Epoch 19/30\n",
      "1116/1116 - 8s - loss: 0.4434 - accuracy: 0.7997 - auc: 0.8489\n",
      "Epoch 20/30\n",
      "1116/1116 - 8s - loss: 0.4434 - accuracy: 0.7998 - auc: 0.8491\n",
      "Epoch 21/30\n",
      "1116/1116 - 8s - loss: 0.4431 - accuracy: 0.7990 - auc: 0.8490\n",
      "Epoch 22/30\n",
      "1116/1116 - 8s - loss: 0.4430 - accuracy: 0.8008 - auc: 0.8490\n",
      "Epoch 23/30\n",
      "1116/1116 - 8s - loss: 0.4430 - accuracy: 0.7999 - auc: 0.8493\n",
      "Epoch 24/30\n",
      "1116/1116 - 8s - loss: 0.4422 - accuracy: 0.8005 - auc: 0.8499\n",
      "Epoch 25/30\n",
      "1116/1116 - 8s - loss: 0.4423 - accuracy: 0.8015 - auc: 0.8500\n",
      "Epoch 26/30\n",
      "1116/1116 - 7s - loss: 0.4422 - accuracy: 0.8002 - auc: 0.8496\n",
      "Epoch 27/30\n",
      "1116/1116 - 8s - loss: 0.4417 - accuracy: 0.8002 - auc: 0.8498\n",
      "Epoch 28/30\n",
      "1116/1116 - 7s - loss: 0.4415 - accuracy: 0.8019 - auc: 0.8503\n",
      "Epoch 29/30\n",
      "1116/1116 - 8s - loss: 0.4425 - accuracy: 0.8008 - auc: 0.8496\n",
      "Epoch 30/30\n",
      "1116/1116 - 8s - loss: 0.4410 - accuracy: 0.8017 - auc: 0.8505\n",
      "Epoch 1/30\n",
      "1116/1116 - 8s - loss: 0.8360 - accuracy: 0.7305 - auc: 0.7672\n",
      "Epoch 2/30\n",
      "1116/1116 - 7s - loss: 0.4722 - accuracy: 0.7803 - auc: 0.8313\n",
      "Epoch 3/30\n",
      "1116/1116 - 8s - loss: 0.4676 - accuracy: 0.7829 - auc: 0.8336\n",
      "Epoch 4/30\n",
      "1116/1116 - 7s - loss: 0.4589 - accuracy: 0.7881 - auc: 0.8391\n",
      "Epoch 5/30\n",
      "1116/1116 - 7s - loss: 0.4585 - accuracy: 0.7874 - auc: 0.8385\n",
      "Epoch 6/30\n",
      "1116/1116 - 7s - loss: 0.4524 - accuracy: 0.7931 - auc: 0.8428\n",
      "Epoch 7/30\n",
      "1116/1116 - 7s - loss: 0.4507 - accuracy: 0.7940 - auc: 0.8433\n",
      "Epoch 8/30\n",
      "1116/1116 - 7s - loss: 0.4490 - accuracy: 0.7942 - auc: 0.8441\n",
      "Epoch 9/30\n",
      "1116/1116 - 7s - loss: 0.4488 - accuracy: 0.7949 - auc: 0.8447\n",
      "Epoch 10/30\n",
      "1116/1116 - 8s - loss: 0.4468 - accuracy: 0.7975 - auc: 0.8461\n",
      "Epoch 11/30\n",
      "1116/1116 - 7s - loss: 0.4451 - accuracy: 0.7972 - auc: 0.8472\n",
      "Epoch 12/30\n",
      "1116/1116 - 8s - loss: 0.4453 - accuracy: 0.7979 - auc: 0.8471\n",
      "Epoch 13/30\n",
      "1116/1116 - 7s - loss: 0.4443 - accuracy: 0.7999 - auc: 0.8477\n",
      "Epoch 14/30\n",
      "1116/1116 - 7s - loss: 0.4442 - accuracy: 0.7987 - auc: 0.8475\n",
      "Epoch 15/30\n",
      "1116/1116 - 7s - loss: 0.4437 - accuracy: 0.7986 - auc: 0.8483\n",
      "Epoch 16/30\n",
      "1116/1116 - 8s - loss: 0.4424 - accuracy: 0.8008 - auc: 0.8493\n",
      "Epoch 17/30\n",
      "1116/1116 - 7s - loss: 0.4428 - accuracy: 0.8005 - auc: 0.8486\n",
      "Epoch 18/30\n",
      "1116/1116 - 7s - loss: 0.4430 - accuracy: 0.7989 - auc: 0.8487\n",
      "Epoch 19/30\n",
      "1116/1116 - 7s - loss: 0.4414 - accuracy: 0.8008 - auc: 0.8495\n",
      "Epoch 20/30\n",
      "1116/1116 - 7s - loss: 0.4414 - accuracy: 0.8019 - auc: 0.8497\n",
      "Epoch 21/30\n",
      "1116/1116 - 7s - loss: 0.4418 - accuracy: 0.8006 - auc: 0.8498\n",
      "Epoch 22/30\n",
      "1116/1116 - 7s - loss: 0.4404 - accuracy: 0.8035 - auc: 0.8507\n",
      "Epoch 23/30\n",
      "1116/1116 - 7s - loss: 0.4416 - accuracy: 0.8017 - auc: 0.8498\n",
      "Epoch 24/30\n",
      "1116/1116 - 7s - loss: 0.4410 - accuracy: 0.8019 - auc: 0.8502\n",
      "Epoch 25/30\n",
      "1116/1116 - 7s - loss: 0.4401 - accuracy: 0.8019 - auc: 0.8508\n",
      "Epoch 26/30\n",
      "1116/1116 - 6s - loss: 0.4407 - accuracy: 0.8019 - auc: 0.8506\n",
      "Epoch 27/30\n",
      "1116/1116 - 6s - loss: 0.4405 - accuracy: 0.8033 - auc: 0.8507\n",
      "Epoch 28/30\n",
      "1116/1116 - 6s - loss: 0.4401 - accuracy: 0.8019 - auc: 0.8508\n",
      "Epoch 29/30\n",
      "1116/1116 - 6s - loss: 0.4397 - accuracy: 0.8034 - auc: 0.8512\n",
      "Epoch 30/30\n",
      "1116/1116 - 6s - loss: 0.4399 - accuracy: 0.8033 - auc: 0.8512\n",
      "Epoch 1/30\n",
      "1116/1116 - 7s - loss: 0.7309 - accuracy: 0.7292 - auc: 0.7661\n",
      "Epoch 2/30\n",
      "1116/1116 - 7s - loss: 0.4769 - accuracy: 0.7779 - auc: 0.8284\n",
      "Epoch 3/30\n",
      "1116/1116 - 6s - loss: 0.4675 - accuracy: 0.7817 - auc: 0.8337\n",
      "Epoch 4/30\n",
      "1116/1116 - 7s - loss: 0.4598 - accuracy: 0.7878 - auc: 0.8382\n",
      "Epoch 5/30\n",
      "1116/1116 - 8s - loss: 0.4586 - accuracy: 0.7877 - auc: 0.8390\n",
      "Epoch 6/30\n",
      "1116/1116 - 8s - loss: 0.4562 - accuracy: 0.7885 - auc: 0.8393\n",
      "Epoch 7/30\n",
      "1116/1116 - 8s - loss: 0.4528 - accuracy: 0.7918 - auc: 0.8420\n",
      "Epoch 8/30\n",
      "1116/1116 - 8s - loss: 0.4501 - accuracy: 0.7930 - auc: 0.8434\n",
      "Epoch 9/30\n",
      "1116/1116 - 8s - loss: 0.4485 - accuracy: 0.7952 - auc: 0.8450\n",
      "Epoch 10/30\n",
      "1116/1116 - 8s - loss: 0.4474 - accuracy: 0.7967 - auc: 0.8459\n",
      "Epoch 11/30\n",
      "1116/1116 - 8s - loss: 0.4478 - accuracy: 0.7946 - auc: 0.8456\n",
      "Epoch 12/30\n",
      "1116/1116 - 8s - loss: 0.4467 - accuracy: 0.7953 - auc: 0.8461\n",
      "Epoch 13/30\n",
      "1116/1116 - 8s - loss: 0.4458 - accuracy: 0.7980 - auc: 0.8472\n",
      "Epoch 14/30\n",
      "1116/1116 - 8s - loss: 0.4447 - accuracy: 0.7979 - auc: 0.8477\n",
      "Epoch 15/30\n",
      "1116/1116 - 8s - loss: 0.4441 - accuracy: 0.7992 - auc: 0.8478\n",
      "Epoch 16/30\n",
      "1116/1116 - 8s - loss: 0.4445 - accuracy: 0.7977 - auc: 0.8473\n",
      "Epoch 17/30\n",
      "1116/1116 - 8s - loss: 0.4428 - accuracy: 0.7997 - auc: 0.8487\n",
      "Epoch 18/30\n",
      "1116/1116 - 8s - loss: 0.4436 - accuracy: 0.7992 - auc: 0.8481\n",
      "Epoch 19/30\n",
      "1116/1116 - 8s - loss: 0.4422 - accuracy: 0.7997 - auc: 0.8492\n",
      "Epoch 20/30\n",
      "1116/1116 - 8s - loss: 0.4417 - accuracy: 0.8003 - auc: 0.8497\n",
      "Epoch 21/30\n",
      "1116/1116 - 8s - loss: 0.4419 - accuracy: 0.8006 - auc: 0.8493\n",
      "Epoch 22/30\n",
      "1116/1116 - 8s - loss: 0.4422 - accuracy: 0.8005 - auc: 0.8496\n",
      "Epoch 23/30\n",
      "1116/1116 - 8s - loss: 0.4418 - accuracy: 0.8010 - auc: 0.8498\n",
      "Epoch 24/30\n",
      "1116/1116 - 8s - loss: 0.4415 - accuracy: 0.8007 - auc: 0.8501\n",
      "Epoch 25/30\n",
      "1116/1116 - 8s - loss: 0.4409 - accuracy: 0.8006 - auc: 0.8504\n",
      "Epoch 26/30\n",
      "1116/1116 - 8s - loss: 0.4417 - accuracy: 0.8017 - auc: 0.8499\n",
      "Epoch 27/30\n",
      "1116/1116 - 8s - loss: 0.4405 - accuracy: 0.8014 - auc: 0.8506\n",
      "Epoch 28/30\n",
      "1116/1116 - 8s - loss: 0.4414 - accuracy: 0.8007 - auc: 0.8499\n",
      "Epoch 29/30\n",
      "1116/1116 - 8s - loss: 0.4415 - accuracy: 0.8015 - auc: 0.8500\n",
      "Epoch 30/30\n",
      "1116/1116 - 8s - loss: 0.4403 - accuracy: 0.8020 - auc: 0.8506\n",
      "Epoch 1/30\n",
      "1116/1116 - 8s - loss: 0.8333 - accuracy: 0.7252 - auc: 0.7581\n",
      "Epoch 2/30\n",
      "1116/1116 - 8s - loss: 0.4811 - accuracy: 0.7740 - auc: 0.8249\n",
      "Epoch 3/30\n",
      "1116/1116 - 8s - loss: 0.4675 - accuracy: 0.7842 - auc: 0.8338\n",
      "Epoch 4/30\n",
      "1116/1116 - 8s - loss: 0.4657 - accuracy: 0.7835 - auc: 0.8345\n",
      "Epoch 5/30\n",
      "1116/1116 - 8s - loss: 0.4610 - accuracy: 0.7871 - auc: 0.8369\n",
      "Epoch 6/30\n",
      "1116/1116 - 8s - loss: 0.4547 - accuracy: 0.7898 - auc: 0.8403\n",
      "Epoch 7/30\n",
      "1116/1116 - 8s - loss: 0.4541 - accuracy: 0.7896 - auc: 0.8401\n",
      "Epoch 8/30\n",
      "1116/1116 - 8s - loss: 0.4491 - accuracy: 0.7932 - auc: 0.8444\n",
      "Epoch 9/30\n",
      "1116/1116 - 8s - loss: 0.4482 - accuracy: 0.7941 - auc: 0.8450\n",
      "Epoch 10/30\n",
      "1116/1116 - 8s - loss: 0.4477 - accuracy: 0.7951 - auc: 0.8457\n",
      "Epoch 11/30\n",
      "1116/1116 - 8s - loss: 0.4468 - accuracy: 0.7954 - auc: 0.8463\n",
      "Epoch 12/30\n",
      "1116/1116 - 8s - loss: 0.4459 - accuracy: 0.7958 - auc: 0.8466\n",
      "Epoch 13/30\n",
      "1116/1116 - 8s - loss: 0.4460 - accuracy: 0.7949 - auc: 0.8467\n",
      "Epoch 14/30\n",
      "1116/1116 - 8s - loss: 0.4454 - accuracy: 0.7959 - auc: 0.8466\n",
      "Epoch 15/30\n",
      "1116/1116 - 8s - loss: 0.4439 - accuracy: 0.7978 - auc: 0.8478\n",
      "Epoch 16/30\n",
      "1116/1116 - 8s - loss: 0.4437 - accuracy: 0.7967 - auc: 0.8477\n",
      "Epoch 17/30\n",
      "1116/1116 - 8s - loss: 0.4438 - accuracy: 0.7975 - auc: 0.8483\n",
      "Epoch 18/30\n",
      "1116/1116 - 8s - loss: 0.4430 - accuracy: 0.7982 - auc: 0.8485\n",
      "Epoch 19/30\n",
      "1116/1116 - 8s - loss: 0.4421 - accuracy: 0.7990 - auc: 0.8488\n",
      "Epoch 20/30\n",
      "1116/1116 - 8s - loss: 0.4415 - accuracy: 0.8008 - auc: 0.8498\n",
      "Epoch 21/30\n",
      "1116/1116 - 8s - loss: 0.4425 - accuracy: 0.7998 - auc: 0.8491\n",
      "Epoch 22/30\n",
      "1116/1116 - 8s - loss: 0.4414 - accuracy: 0.8009 - auc: 0.8500\n",
      "Epoch 23/30\n",
      "1116/1116 - 8s - loss: 0.4423 - accuracy: 0.7995 - auc: 0.8490\n",
      "Epoch 24/30\n",
      "1116/1116 - 8s - loss: 0.4412 - accuracy: 0.8003 - auc: 0.8501\n",
      "Epoch 25/30\n",
      "1116/1116 - 8s - loss: 0.4413 - accuracy: 0.8011 - auc: 0.8500\n",
      "Epoch 26/30\n",
      "1116/1116 - 8s - loss: 0.4413 - accuracy: 0.8007 - auc: 0.8500\n",
      "Epoch 27/30\n",
      "1116/1116 - 8s - loss: 0.4408 - accuracy: 0.8008 - auc: 0.8502\n",
      "Epoch 28/30\n",
      "1116/1116 - 8s - loss: 0.4403 - accuracy: 0.8008 - auc: 0.8504\n",
      "Epoch 29/30\n",
      "1116/1116 - 8s - loss: 0.4408 - accuracy: 0.8004 - auc: 0.8501\n",
      "Epoch 30/30\n",
      "1116/1116 - 8s - loss: 0.4409 - accuracy: 0.8006 - auc: 0.8499\n",
      "Epoch 1/30\n",
      "1116/1116 - 8s - loss: 0.6428 - accuracy: 0.7367 - auc: 0.7740\n",
      "Epoch 2/30\n",
      "1116/1116 - 8s - loss: 0.4741 - accuracy: 0.7789 - auc: 0.8299\n",
      "Epoch 3/30\n",
      "1116/1116 - 8s - loss: 0.4649 - accuracy: 0.7836 - auc: 0.8344\n",
      "Epoch 4/30\n",
      "1116/1116 - 8s - loss: 0.4611 - accuracy: 0.7865 - auc: 0.8363\n",
      "Epoch 5/30\n",
      "1116/1116 - 8s - loss: 0.4555 - accuracy: 0.7892 - auc: 0.8402\n",
      "Epoch 6/30\n",
      "1116/1116 - 8s - loss: 0.4541 - accuracy: 0.7899 - auc: 0.8407\n",
      "Epoch 7/30\n",
      "1116/1116 - 8s - loss: 0.4523 - accuracy: 0.7913 - auc: 0.8417\n",
      "Epoch 8/30\n",
      "1116/1116 - 8s - loss: 0.4499 - accuracy: 0.7934 - auc: 0.8440\n",
      "Epoch 9/30\n",
      "1116/1116 - 8s - loss: 0.4486 - accuracy: 0.7941 - auc: 0.8447\n",
      "Epoch 10/30\n",
      "1116/1116 - 8s - loss: 0.4484 - accuracy: 0.7947 - auc: 0.8451\n",
      "Epoch 11/30\n",
      "1116/1116 - 8s - loss: 0.4462 - accuracy: 0.7959 - auc: 0.8462\n",
      "Epoch 12/30\n",
      "1116/1116 - 8s - loss: 0.4466 - accuracy: 0.7956 - auc: 0.8458\n",
      "Epoch 13/30\n",
      "1116/1116 - 8s - loss: 0.4453 - accuracy: 0.7965 - auc: 0.8471\n",
      "Epoch 14/30\n",
      "1116/1116 - 8s - loss: 0.4446 - accuracy: 0.7970 - auc: 0.8473\n",
      "Epoch 15/30\n",
      "1116/1116 - 8s - loss: 0.4444 - accuracy: 0.7976 - auc: 0.8480\n",
      "Epoch 16/30\n",
      "1116/1116 - 8s - loss: 0.4441 - accuracy: 0.7980 - auc: 0.8478\n",
      "Epoch 17/30\n",
      "1116/1116 - 8s - loss: 0.4429 - accuracy: 0.7987 - auc: 0.8488\n",
      "Epoch 18/30\n",
      "1116/1116 - 8s - loss: 0.4440 - accuracy: 0.7984 - auc: 0.8482\n",
      "Epoch 19/30\n",
      "1116/1116 - 8s - loss: 0.4427 - accuracy: 0.7994 - auc: 0.8485\n",
      "Epoch 20/30\n",
      "1116/1116 - 8s - loss: 0.4424 - accuracy: 0.7999 - auc: 0.8492\n",
      "Epoch 21/30\n",
      "1116/1116 - 8s - loss: 0.4420 - accuracy: 0.7997 - auc: 0.8495\n",
      "Epoch 22/30\n",
      "1116/1116 - 8s - loss: 0.4417 - accuracy: 0.7989 - auc: 0.8498\n",
      "Epoch 23/30\n",
      "1116/1116 - 8s - loss: 0.4421 - accuracy: 0.7992 - auc: 0.8494\n",
      "Epoch 24/30\n",
      "1116/1116 - 8s - loss: 0.4411 - accuracy: 0.7999 - auc: 0.8498\n",
      "Epoch 25/30\n",
      "1116/1116 - 8s - loss: 0.4424 - accuracy: 0.7996 - auc: 0.8490\n",
      "Epoch 26/30\n",
      "1116/1116 - 8s - loss: 0.4408 - accuracy: 0.8010 - auc: 0.8503\n",
      "Epoch 27/30\n",
      "1116/1116 - 8s - loss: 0.4404 - accuracy: 0.8022 - auc: 0.8507\n",
      "Epoch 28/30\n",
      "1116/1116 - 8s - loss: 0.4412 - accuracy: 0.8006 - auc: 0.8499\n",
      "Epoch 29/30\n",
      "1116/1116 - 8s - loss: 0.4410 - accuracy: 0.8008 - auc: 0.8502\n",
      "Epoch 30/30\n",
      "1116/1116 - 8s - loss: 0.4402 - accuracy: 0.8018 - auc: 0.8507\n",
      "Epoch 1/30\n",
      "1116/1116 - 8s - loss: 0.6241 - accuracy: 0.7346 - auc: 0.7751\n",
      "Epoch 2/30\n",
      "1116/1116 - 8s - loss: 0.4723 - accuracy: 0.7797 - auc: 0.8301\n",
      "Epoch 3/30\n",
      "1116/1116 - 8s - loss: 0.4651 - accuracy: 0.7849 - auc: 0.8344\n",
      "Epoch 4/30\n",
      "1116/1116 - 8s - loss: 0.4604 - accuracy: 0.7880 - auc: 0.8367\n",
      "Epoch 5/30\n",
      "1116/1116 - 8s - loss: 0.4566 - accuracy: 0.7895 - auc: 0.8385\n",
      "Epoch 6/30\n",
      "1116/1116 - 7s - loss: 0.4538 - accuracy: 0.7915 - auc: 0.8408\n",
      "Epoch 7/30\n",
      "1116/1116 - 8s - loss: 0.4500 - accuracy: 0.7932 - auc: 0.8434\n",
      "Epoch 8/30\n",
      "1116/1116 - 8s - loss: 0.4503 - accuracy: 0.7941 - auc: 0.8430\n",
      "Epoch 9/30\n",
      "1116/1116 - 8s - loss: 0.4480 - accuracy: 0.7954 - auc: 0.8446\n",
      "Epoch 10/30\n",
      "1116/1116 - 8s - loss: 0.4478 - accuracy: 0.7960 - auc: 0.8449\n",
      "Epoch 11/30\n",
      "1116/1116 - 8s - loss: 0.4452 - accuracy: 0.7970 - auc: 0.8469\n",
      "Epoch 12/30\n",
      "1116/1116 - 8s - loss: 0.4445 - accuracy: 0.7983 - auc: 0.8471\n",
      "Epoch 13/30\n",
      "1116/1116 - 8s - loss: 0.4449 - accuracy: 0.7978 - auc: 0.8474\n",
      "Epoch 14/30\n",
      "1116/1116 - 8s - loss: 0.4435 - accuracy: 0.7988 - auc: 0.8487\n",
      "Epoch 15/30\n",
      "1116/1116 - 8s - loss: 0.4431 - accuracy: 0.7997 - auc: 0.8478\n",
      "Epoch 16/30\n",
      "1116/1116 - 8s - loss: 0.4430 - accuracy: 0.7997 - auc: 0.8487\n",
      "Epoch 17/30\n",
      "1116/1116 - 8s - loss: 0.4425 - accuracy: 0.7998 - auc: 0.8482\n",
      "Epoch 18/30\n",
      "1116/1116 - 8s - loss: 0.4416 - accuracy: 0.8007 - auc: 0.8493\n",
      "Epoch 19/30\n",
      "1116/1116 - 8s - loss: 0.4422 - accuracy: 0.8002 - auc: 0.8489\n",
      "Epoch 20/30\n",
      "1116/1116 - 8s - loss: 0.4424 - accuracy: 0.8004 - auc: 0.8489\n",
      "Epoch 21/30\n",
      "1116/1116 - 8s - loss: 0.4419 - accuracy: 0.8012 - auc: 0.8490\n",
      "Epoch 22/30\n",
      "1116/1116 - 8s - loss: 0.4406 - accuracy: 0.8017 - auc: 0.8501\n",
      "Epoch 23/30\n",
      "1116/1116 - 8s - loss: 0.4422 - accuracy: 0.7993 - auc: 0.8487\n",
      "Epoch 24/30\n",
      "1116/1116 - 8s - loss: 0.4409 - accuracy: 0.8008 - auc: 0.8502\n",
      "Epoch 25/30\n",
      "1116/1116 - 8s - loss: 0.4407 - accuracy: 0.8020 - auc: 0.8496\n",
      "Epoch 26/30\n",
      "1116/1116 - 8s - loss: 0.4407 - accuracy: 0.8015 - auc: 0.8500\n",
      "Epoch 27/30\n",
      "1116/1116 - 8s - loss: 0.4404 - accuracy: 0.8008 - auc: 0.8501\n",
      "Epoch 28/30\n",
      "1116/1116 - 8s - loss: 0.4408 - accuracy: 0.8017 - auc: 0.8501\n",
      "Epoch 29/30\n",
      "1116/1116 - 8s - loss: 0.4408 - accuracy: 0.8009 - auc: 0.8499\n",
      "Epoch 30/30\n",
      "1116/1116 - 8s - loss: 0.4401 - accuracy: 0.8027 - auc: 0.8507\n"
     ]
    }
   ],
   "source": [
    "# 10 fold\n",
    "kfolds = 10 # 4 = 75% train, 25% validation\n",
    "split = KFold(n_splits=kfolds, shuffle=True, random_state=42)\n",
    "\n",
    "X = city_data.drop([\"is_canceled\"], axis=1)[features]\n",
    "y = city_data[\"is_canceled\"].to_numpy()\n",
    "\n",
    "X = preprocessor.fit_transform(X)\n",
    "\n",
    "result = []\n",
    "\n",
    "for train_index, test_index in split.split(y):\n",
    "    train_x = X[train_index]\n",
    "    train_y = y[train_index]\n",
    "    \n",
    "    test_x = X[test_index]\n",
    "    test_y = y[test_index]\n",
    "    \n",
    "    model = test_model_1()\n",
    "    \n",
    "    history = model.fit(train_x, train_y, batch_size=64, epochs=30, verbose = 2)\n",
    "    pred_y = model.predict(test_x)\n",
    "    result.append({'pred': pred_y, 'test': test_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_accuracy = []\n",
    "total_f1 = []\n",
    "total_pre = []\n",
    "total_recall = []\n",
    "total_auc = []\n",
    "for i in range(10):\n",
    "    pred = result[i]['pred']\n",
    "    test = result[i]['test']\n",
    "    fpr, tpr, _ = roc_curve(test, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    total_auc.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=0.8)\n",
    "    t_acc = []\n",
    "    t_f1 = []\n",
    "    t_pre = []\n",
    "    t_rec = []\n",
    "    for t in np.arange(0,1,0.05):\n",
    "        p_val = np.zeros(pred.shape)\n",
    "        p_val[pred > t] = 1\n",
    "        t_acc.append(accuracy_score(test, p_val))\n",
    "        t_f1.append(f1_score(test, p_val))\n",
    "        t_pre.append(precision_score(test, p_val))\n",
    "        t_rec.append(recall_score(test, p_val)) \n",
    "    total_accuracy.append(np.max(t_acc))\n",
    "    total_f1.append(np.max(t_f1))\n",
    "    total_pre.append(np.max(t_pre))\n",
    "    total_recall.append(np.max(t_rec)) \n",
    "    \n",
    "plt.savefig('cityDNN.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_res = {'auc':total_auc, 'acc': total_accuracy, 'f1': total_f1,\n",
    "            'pre': total_pre, 'recall': total_recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc \t 0.8487523264374119 0.8561268731725146 0.8522780115819406\n",
      "acc \t 0.797554519097441 0.8145720408420521 0.8054077902432875\n",
      "f1 \t 0.7384068508644368 0.7592865324824087 0.7471323839448493\n",
      "pre \t 0.9947328818660647 0.9984202211690363 0.9966834296048847\n",
      "recall \t 1.0 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# total\n",
    "for k, v in total_res.items():\n",
    "    print(k, '\\t', min(v), max(v), np.average(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': [0.8547715016801155,\n",
       "  0.8544909127110658,\n",
       "  0.8492863194516571,\n",
       "  0.8490837262238053,\n",
       "  0.8499610086154883,\n",
       "  0.8487523264374119,\n",
       "  0.8523203697997079,\n",
       "  0.8561268731725146,\n",
       "  0.8542615145511545,\n",
       "  0.8537255631764864],\n",
       " 'acc': [0.8060002521114332,\n",
       "  0.8043615277952855,\n",
       "  0.803100970629018,\n",
       "  0.8053699735282995,\n",
       "  0.8080171435774612,\n",
       "  0.7994453548468423,\n",
       "  0.8065044749779402,\n",
       "  0.8145720408420521,\n",
       "  0.809151645027102,\n",
       "  0.797554519097441],\n",
       " 'f1': [0.7487891507910882,\n",
       "  0.7488712439669936,\n",
       "  0.74496,\n",
       "  0.7448754336171556,\n",
       "  0.746268656716418,\n",
       "  0.7384068508644368,\n",
       "  0.7441495209674887,\n",
       "  0.7592865324824087,\n",
       "  0.7487429034874291,\n",
       "  0.7469735465550741],\n",
       " 'pre': [0.9984202211690363,\n",
       "  0.9969947407963937,\n",
       "  0.9947328818660647,\n",
       "  0.9975708502024292,\n",
       "  0.9977186311787072,\n",
       "  0.9956204379562044,\n",
       "  0.9976228209191759,\n",
       "  0.9950877192982456,\n",
       "  0.9968798751950078,\n",
       "  0.996186117467582],\n",
       " 'recall': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8522780115819406"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(total_res['auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8054077902432875"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(total_res['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
